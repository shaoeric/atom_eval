{"index": 22, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªåŸå¸‚ä¸­ä¸åŒæ€§åˆ«çš„ç”¨æˆ·æ•°é‡ï¼Œä½¿ç”¨é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºã€‚\nSQL:", "target": "SELECT city, SUM(CASE WHEN gender = 'male' THEN 1 ELSE 0 END) as male_count, SUM(CASE WHEN gender = 'female' THEN 1 ELSE 0 END) as female_count, SUM(CASE WHEN gender NOT IN ('male', 'female') OR gender IS NULL THEN 1 ELSE 0 END) as other_count FROM users GROUP BY city;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.52}, "extracted_prediction": "SELECT      city,     SUM(CASE WHEN gender = 'Male' THEN 1 ELSE 0 END) AS Male,     SUM(CASE WHEN gender = 'Female' THEN 1 ELSE 0 END) AS Female FROM users WHERE city IS NOT NULL GROUP BY city ORDER BY city", "prediction": "è¦ç»Ÿè®¡æ¯ä¸ªåŸå¸‚ä¸­ä¸åŒæ€§åˆ«çš„ç”¨æˆ·æ•°é‡ï¼Œå¹¶ä»¥é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºï¼ˆå³æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªåŸå¸‚ï¼Œæ¯ä¸€åˆ—æ˜¯æ€§åˆ«ï¼Œå•å…ƒæ ¼æ˜¯å¯¹åº”æ•°é‡ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ `CASE` è¯­å¥é…åˆ `SUM` è¿›è¡Œæ¡ä»¶èšåˆï¼Œæˆ–è€…ä½¿ç”¨ `GROUP BY` + `PIVOT`ï¼ˆå¦‚æœæ•°æ®åº“æ”¯æŒï¼Œå¦‚ SQL Serverã€Oracleï¼‰ã€‚ä½† SQLite å’Œ MySQL ä¸åŸç”Ÿæ”¯æŒ `PIVOT`ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨æ ‡å‡† SQL çš„æ¡ä»¶èšåˆæ–¹å¼ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ•°æ®åº“ã€‚\n\nå‡è®¾æ€§åˆ«å­—æ®µ `gender` çš„å€¼ä¸º `'Male'` å’Œ `'Female'`ï¼ˆæ ¹æ®å¸¸è§æ•°æ®ï¼‰ï¼ŒSQL æŸ¥è¯¢å¦‚ä¸‹ï¼š\n\n```sql\nSELECT \n    city,\n    SUM(CASE WHEN gender = 'Male' THEN 1 ELSE 0 END) AS Male,\n    SUM(CASE WHEN gender = 'Female' THEN 1 ELSE 0 END) AS Female\nFROM users\nWHERE city IS NOT NULL\nGROUP BY city\nORDER BY city;\n```\n\n### è¯´æ˜ï¼š\n- `SUM(CASE WHEN gender = 'Male' THEN 1 ELSE 0 END)`ï¼šç»Ÿè®¡æ¯ä¸ªåŸå¸‚ä¸­ç”·æ€§ç”¨æˆ·æ•°é‡ã€‚\n- `SUM(CASE WHEN gender = 'Female' THEN 1 ELSE 0 END)`ï¼šç»Ÿè®¡æ¯ä¸ªåŸå¸‚ä¸­å¥³æ€§ç”¨æˆ·æ•°é‡ã€‚\n- `WHERE city IS NOT NULL`ï¼šæ’é™¤åŸå¸‚ä¸ºç©ºçš„è®°å½•ï¼ˆå¯é€‰ï¼Œè§†éœ€æ±‚è€Œå®šï¼‰ã€‚\n- `GROUP BY city`ï¼šæŒ‰åŸå¸‚åˆ†ç»„ã€‚\n- `ORDER BY city`ï¼šæŒ‰åŸå¸‚åç§°æ’åºï¼Œä¾¿äºé˜…è¯»ã€‚\n\n### è¾“å‡ºç¤ºä¾‹ï¼š\n| city       | Male | Female |\n|------------|------|--------|\n| Beijing    | 120  | 135    |\n| Shanghai   | 98   | 110    |\n| Guangzhou  | 85   | 92     |\n\n> âœ… æ­¤æŸ¥è¯¢å…¼å®¹ MySQLã€PostgreSQLã€SQLiteã€SQL Server ç­‰ä¸»æµæ•°æ®åº“ï¼Œæ— éœ€ä½¿ç”¨éæ ‡å‡†çš„ `PIVOT` è¯­æ³•ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 22, "group_id": 22, "sample_metadata": {}}}
{"index": 50, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æ–‡ä»¶å¤§å°åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„æ–‡æ¡£ï¼ŒæŒ‰ç±»åˆ«åˆ†ç»„ç»Ÿè®¡æ•°é‡ï¼Œåªæ˜¾ç¤ºæ•°é‡å¤§äº5çš„ç±»åˆ«ã€‚\nSQL:", "target": "SELECT category, COUNT(*) as count FROM research_docs WHERE file_size > (SELECT AVG(file_size) FROM research_docs) GROUP BY category HAVING COUNT(*) > 5;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT category, COUNT(*) AS count FROM research_docs WHERE file_size > (SELECT AVG(file_size) FROM research_docs) GROUP BY category HAVING COUNT(*) > 5", "prediction": "SELECT category, COUNT(*) AS count\nFROM research_docs\nWHERE file_size > (SELECT AVG(file_size) FROM research_docs)\nGROUP BY category\nHAVING COUNT(*) > 5;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 50, "group_id": 50, "sample_metadata": {}}}
{"index": 70, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢é¡µé¢URLåŒ…å«'product'çš„æ—¥å¿—ï¼Œç»Ÿè®¡æ¯ä¸ªæ“ä½œç±»å‹çš„æ—¥å¿—æ•°é‡ã€‚\nSQL:", "target": "SELECT action_type, COUNT(*) as count FROM user_interaction_logs WHERE page_url LIKE '%product%' GROUP BY action_type;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.96875}, "extracted_prediction": "SELECT action_type, COUNT(*) AS log_count FROM user_interaction_logs WHERE page_url LIKE '%product%' GROUP BY action_type", "prediction": "SELECT action_type, COUNT(*) AS log_count\nFROM user_interaction_logs\nWHERE page_url LIKE '%product%'\nGROUP BY action_type;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 70, "group_id": 70, "sample_metadata": {}}}
{"index": 49, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªçŠ¶æ€çš„æ–‡æ¡£æ•°é‡å’Œæ€»æ–‡ä»¶å¤§å°ï¼ŒæŒ‰æ€»æ–‡ä»¶å¤§å°é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT status, COUNT(*) as count, SUM(file_size) as total_size FROM research_docs GROUP BY status ORDER BY total_size DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7708333333333334}, "extracted_prediction": "SELECT      status,      COUNT(*) AS doc_count,      SUM(file_size) AS total_file_size FROM      research_docs GROUP BY      status ORDER BY      total_file_size DESC", "prediction": "SELECT \n    status, \n    COUNT(*) AS doc_count, \n    SUM(file_size) AS total_file_size\nFROM \n    research_docs\nGROUP BY \n    status\nORDER BY \n    total_file_size DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 49, "group_id": 49, "sample_metadata": {}}}
{"index": 69, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æ‰¾å‡ºæ“ä½œæ—¶é•¿åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„æ—¥å¿—ï¼ŒæŒ‰ç”¨æˆ·IDåˆ†ç»„ç»Ÿè®¡æ•°é‡ï¼Œåªæ˜¾ç¤ºæ•°é‡å¤§äº20çš„ç”¨æˆ·ã€‚\nSQL:", "target": "SELECT user_id, COUNT(*) as count FROM user_interaction_logs WHERE duration > (SELECT AVG(duration) FROM user_interaction_logs) GROUP BY user_id HAVING COUNT(*) > 20;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9800000000000001}, "extracted_prediction": "SELECT      user_id,      COUNT(*) AS log_count FROM      user_interaction_logs WHERE      duration > (SELECT AVG(duration) FROM user_interaction_logs) GROUP BY      user_id HAVING      COUNT(*) > 20", "prediction": "SELECT \n    user_id, \n    COUNT(*) AS log_count\nFROM \n    user_interaction_logs\nWHERE \n    duration > (SELECT AVG(duration) FROM user_interaction_logs)\nGROUP BY \n    user_id\nHAVING \n    COUNT(*) > 20;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 69, "group_id": 69, "sample_metadata": {}}}
{"index": 63, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢æœ€è¿‘7å¤©å†…è®¿é—®çš„ç”¨æˆ·äº¤äº’æ—¥å¿—ï¼Œç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„æ“ä½œæ¬¡æ•°ï¼Œåªæ˜¾ç¤ºæ“ä½œæ¬¡æ•°è¶…è¿‡50çš„ç”¨æˆ·ï¼ŒæŒ‰æ“ä½œæ¬¡æ•°é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT user_id, COUNT(*) as action_count FROM user_interaction_logs WHERE timestamp >= datetime('now', '-7 days') GROUP BY user_id HAVING COUNT(*) > 50 ORDER BY action_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9259259259259259}, "extracted_prediction": "SELECT      user_id,      COUNT(*) AS action_count FROM      user_interaction_logs WHERE      timestamp >= NOW() - INTERVAL '7 days' GROUP BY      user_id HAVING      COUNT(*) > 50 ORDER BY      action_count DESC", "prediction": "SELECT \n    user_id, \n    COUNT(*) AS action_count\nFROM \n    user_interaction_logs\nWHERE \n    timestamp >= NOW() - INTERVAL '7 days'\nGROUP BY \n    user_id\nHAVING \n    COUNT(*) > 50\nORDER BY \n    action_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 63, "group_id": 63, "sample_metadata": {}}}
{"index": 48, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æ‰¾å‡ºæ ‡é¢˜ä¸­åŒ…å«'ç®—æ³•'æˆ–'è®¾è®¡'çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜ã€ç±»åˆ«å’Œåˆ›å»ºæ—¥æœŸï¼ŒæŒ‰åˆ›å»ºæ—¥æœŸé™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT doc_id, title, category, created_date FROM research_docs WHERE title LIKE '%ç®—æ³•%' OR title LIKE '%è®¾è®¡%' ORDER BY created_date DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT doc_id, title, category, created_date FROM research_docs WHERE title LIKE '%ç®—æ³•%' OR title LIKE '%è®¾è®¡%' ORDER BY created_date DESC", "prediction": "SELECT doc_id, title, category, created_date\nFROM research_docs\nWHERE title LIKE '%ç®—æ³•%' OR title LIKE '%è®¾è®¡%'\nORDER BY created_date DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 48, "group_id": 48, "sample_metadata": {}}}
{"index": 68, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢2023å¹´æ¯ä¸ªæœˆçš„æ—¥å¿—æ•°é‡ï¼Œåªæ˜¾ç¤ºæ—¥å¿—æ•°é‡è¶…è¿‡10000çš„æœˆä»½ï¼ŒæŒ‰æœˆä»½æ’åºã€‚\nSQL:", "target": "SELECT strftime('%Y-%m', timestamp) as month, COUNT(*) as log_count FROM user_interaction_logs WHERE strftime('%Y', timestamp) = '2023' GROUP BY month HAVING COUNT(*) > 10000 ORDER BY month;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      strftime('%Y-%m', timestamp) AS month,     COUNT(*) AS log_count FROM      user_interaction_logs WHERE      strftime('%Y', timestamp) = '2023' GROUP BY      month HAVING      COUNT(*) > 10000 ORDER BY      month", "prediction": "SELECT \n    strftime('%Y-%m', timestamp) AS month,\n    COUNT(*) AS log_count\nFROM \n    user_interaction_logs\nWHERE \n    strftime('%Y', timestamp) = '2023'\nGROUP BY \n    month\nHAVING \n    COUNT(*) > 10000\nORDER BY \n    month;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 68, "group_id": 68, "sample_metadata": {}}}
{"index": 16, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢æ³¨å†Œæ—¶é—´è·ç¦»ä»Šå¤©æ­£å¥½365å¤©çš„ç”¨æˆ·æ•°é‡ã€‚\nSQL:", "target": "SELECT COUNT(*) FROM users WHERE registration_date = DATE('now', '-365 days');", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT COUNT(*)  FROM users  WHERE registration_date = DATE('now', '-365 days')", "prediction": "SELECT COUNT(*) \nFROM users \nWHERE registration_date = DATE('now', '-365 days');", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 16, "group_id": 16, "sample_metadata": {}}}
{"index": 47, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æœ€è¿‘6ä¸ªæœˆå†…æ›´æ–°çš„æ–‡æ¡£ï¼Œæ‰¾å‡ºæ¯ä¸ªä½œè€…æ›´æ–°çš„æ–‡æ¡£æ•°é‡ï¼Œåªæ˜¾ç¤ºæ›´æ–°æ•°é‡å¤§äº10çš„ä½œè€…ã€‚\nSQL:", "target": "SELECT author, COUNT(*) as update_count FROM research_docs WHERE updated_date >= DATE('now', '-6 months') GROUP BY author HAVING COUNT(*) > 10 ORDER BY update_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8333333333333334}, "extracted_prediction": "SELECT author, COUNT(*) AS update_count FROM research_docs WHERE updated_date >= DATE('now', '-6 months') GROUP BY author HAVING COUNT(*) > 10", "prediction": "SELECT author, COUNT(*) AS update_count\nFROM research_docs\nWHERE updated_date >= DATE('now', '-6 months')\nGROUP BY author\nHAVING COUNT(*) > 10;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 47, "group_id": 47, "sample_metadata": {}}}
{"index": 75, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: ç»Ÿè®¡2023å¹´æ¯ä¸ªå­£åº¦çš„æ—¥å¿—æ€»æ•°é‡å’Œå¹³å‡æ“ä½œæ—¶é•¿ï¼ŒæŒ‰å­£åº¦æ’åºã€‚\nSQL:", "target": "SELECT CASE WHEN strftime('%m', timestamp) IN ('01','02','03') THEN 'Q1' WHEN strftime('%m', timestamp) IN ('04','05','06') THEN 'Q2' WHEN strftime('%m', timestamp) IN ('07','08','09') THEN 'Q3' ELSE 'Q4' END as quarter, COUNT(*) as total_count, AVG(duration) as avg_duration FROM user_interaction_logs WHERE strftime('%Y', timestamp) = '2023' GROUP BY quarter ORDER BY quarter;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.6436507936507937}, "extracted_prediction": "SELECT      QUARTER(timestamp) AS quarter,     COUNT(*) AS total_logs,     AVG(duration) AS avg_duration FROM      user_interaction_logs WHERE      YEAR(timestamp) = 2023 GROUP BY      QUARTER(timestamp) ORDER BY      quarter", "prediction": "SELECT \n    QUARTER(timestamp) AS quarter,\n    COUNT(*) AS total_logs,\n    AVG(duration) AS avg_duration\nFROM \n    user_interaction_logs\nWHERE \n    YEAR(timestamp) = 2023\nGROUP BY \n    QUARTER(timestamp)\nORDER BY \n    quarter;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 75, "group_id": 75, "sample_metadata": {}}}
{"index": 25, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢è®¢å•æ€»é‡‘é¢è¶…è¿‡10000å…ƒçš„è®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·ã€ç”¨æˆ·IDã€è®¢å•é‡‘é¢å’Œä¸‹å•æ—¶é—´ï¼ŒæŒ‰é‡‘é¢é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT order_id, user_id, total_amount, order_date FROM orders WHERE total_amount > 10000 ORDER BY total_amount DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9166666666666666}, "extracted_prediction": "SELECT order_id, user_id, total_amount, created_at FROM orders WHERE total_amount > 10000 ORDER BY total_amount DESC", "prediction": "SELECT order_id, user_id, total_amount, created_at\nFROM orders\nWHERE total_amount > 10000\nORDER BY total_amount DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 25, "group_id": 25, "sample_metadata": {}}}
{"index": 74, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢çŠ¶æ€ç ä¸ä¸º200çš„æ—¥å¿—ï¼Œç»Ÿè®¡æ¯ä¸ªçŠ¶æ€ç çš„æ—¥å¿—æ•°é‡å’Œå¹³å‡æ“ä½œæ—¶é•¿ã€‚\nSQL:", "target": "SELECT status_code, COUNT(*) as count, AVG(duration) as avg_duration FROM user_interaction_logs WHERE status_code != 200 GROUP BY status_code ORDER BY count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7818181818181819}, "extracted_prediction": "SELECT      status_code,      COUNT(*) AS log_count,      AVG(duration) AS avg_duration FROM      user_interaction_logs WHERE      status_code != 200 GROUP BY      status_code", "prediction": "SELECT \n    status_code, \n    COUNT(*) AS log_count, \n    AVG(duration) AS avg_duration\nFROM \n    user_interaction_logs\nWHERE \n    status_code != 200\nGROUP BY \n    status_code;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 74, "group_id": 74, "sample_metadata": {}}}
{"index": 35, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢æŠ˜æ‰£ç‡ï¼ˆæŠ˜æ‰£é‡‘é¢/æ€»é‡‘é¢ï¼‰å¤§äº0.2çš„è®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·ã€æ€»é‡‘é¢ã€æŠ˜æ‰£é‡‘é¢å’ŒæŠ˜æ‰£ç‡ï¼ŒæŒ‰æŠ˜æ‰£ç‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT order_id, total_amount, discount, ROUND(discount * 100.0 / total_amount, 2) as discount_rate FROM orders WHERE discount * 1.0 / total_amount > 0.2 ORDER BY discount_rate DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8730769230769231}, "extracted_prediction": "SELECT      order_id,     total_amount,     discount,     CAST(discount AS DECIMAL(10,2)) / total_amount AS discount_rate FROM      orders WHERE      discount / total_amount > 0.2 ORDER BY      discount_rate DESC", "prediction": "SELECT \n    order_id,\n    total_amount,\n    discount,\n    CAST(discount AS DECIMAL(10,2)) / total_amount AS discount_rate\nFROM \n    orders\nWHERE \n    discount / total_amount > 0.2\nORDER BY \n    discount_rate DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 35, "group_id": 35, "sample_metadata": {}}}
{"index": 46, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ–‡æ¡£æ•°é‡å’Œå¹³å‡æ–‡ä»¶å¤§å°ï¼ŒæŒ‰æ–‡æ¡£æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT category, COUNT(*) as doc_count, AVG(file_size) as avg_size FROM research_docs GROUP BY category ORDER BY doc_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9583333333333334}, "extracted_prediction": "SELECT      category,      COUNT(*) AS doc_count,      AVG(file_size) AS avg_file_size FROM      research_docs GROUP BY      category ORDER BY      doc_count DESC", "prediction": "SELECT \n    category, \n    COUNT(*) AS doc_count, \n    AVG(file_size) AS avg_file_size\nFROM \n    research_docs\nGROUP BY \n    category\nORDER BY \n    doc_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 46, "group_id": 46, "sample_metadata": {}}}
{"index": 21, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢çŠ¶æ€ä¸ºæ´»è·ƒä¸”å¹´é¾„åœ¨25-40å²ä¹‹é—´çš„å¥³æ€§ç”¨æˆ·ï¼ŒæŒ‰å¹´é¾„å‡åºæ’åˆ—ï¼Œæ˜¾ç¤ºå‰20æ¡ã€‚\nSQL:", "target": "SELECT * FROM users WHERE status = 'active' AND age BETWEEN 25 AND 40 AND gender = 'female' ORDER BY age ASC LIMIT 20;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT * FROM users WHERE status = 'active'   AND gender = 'female'   AND age BETWEEN 25 AND 40 ORDER BY age ASC LIMIT 20", "prediction": "SELECT *\nFROM users\nWHERE status = 'active'\n  AND gender = 'female'\n  AND age BETWEEN 25 AND 40\nORDER BY age ASC\nLIMIT 20;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 21, "group_id": 21, "sample_metadata": {}}}
{"index": 79, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæ“ä½œç±»å‹åœ¨ä¸åŒè®¾å¤‡ç±»å‹ä¸‹çš„å¹³å‡æ“ä½œæ—¶é•¿ï¼Œä½¿ç”¨é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºã€‚\nSQL:", "target": "SELECT action_type, AVG(CASE WHEN device_type = 'desktop' THEN duration END) as desktop_avg, AVG(CASE WHEN device_type = 'mobile' THEN duration END) as mobile_avg, AVG(CASE WHEN device_type = 'tablet' THEN duration END) as tablet_avg FROM user_interaction_logs GROUP BY action_type;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.54}, "extracted_prediction": "SELECT      action_type,     AVG(CASE WHEN device_type = 'desktop' THEN duration END) AS avg_duration_desktop,     AVG(CASE WHEN device_type = 'mobile' THEN duration END) AS avg_duration_mobile,     AVG(CASE WHEN device_type = 'tablet' THEN duration END) AS avg_duration_tablet FROM      user_interaction_logs WHERE      duration IS NOT NULL GROUP BY      action_type ORDER BY      action_type", "prediction": "è¦å°†é—®é¢˜â€œç»Ÿè®¡æ¯ä¸ªæ“ä½œç±»å‹åœ¨ä¸åŒè®¾å¤‡ç±»å‹ä¸‹çš„å¹³å‡æ“ä½œæ—¶é•¿ï¼Œä½¿ç”¨é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºâ€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ï¼š\n\n- æŒ‰ `action_type`ï¼ˆæ“ä½œç±»å‹ï¼‰å’Œ `device_type`ï¼ˆè®¾å¤‡ç±»å‹ï¼‰åˆ†ç»„ï¼›\n- è®¡ç®—æ¯ä¸ªç»„åˆçš„å¹³å‡ `duration`ï¼ˆæ“ä½œæ—¶é•¿ï¼‰ï¼›\n- ä½¿ç”¨**é€è§†è¡¨æ ¼å¼**ï¼ˆå³ï¼šå°† `device_type` ä½œä¸ºåˆ—ï¼Œ`action_type` ä½œä¸ºè¡Œï¼Œæ¯ä¸ªå•å…ƒæ ¼æ˜¯å¹³å‡æ—¶é•¿ï¼‰ã€‚\n\nç”±äºæ ‡å‡† SQL ä¸ç›´æ¥æ”¯æŒåŠ¨æ€åˆ—çš„é€è§†ï¼ˆPivotï¼‰ï¼Œæˆ‘ä»¬éœ€**æ‰‹åŠ¨ä½¿ç”¨ CASE è¡¨è¾¾å¼**è¿›è¡Œé™æ€é€è§†ï¼ˆå‡è®¾å·²çŸ¥æ‰€æœ‰å¯èƒ½çš„ `device_type` å€¼ï¼Œå¦‚ 'desktop', 'mobile', 'tablet' ç­‰ï¼‰ã€‚\n\n### å‡è®¾è®¾å¤‡ç±»å‹åŒ…æ‹¬ï¼š\n- 'desktop'\n- 'mobile'\n- 'tablet'\n\nï¼ˆå¦‚å®é™…æ•°æ®ä¸­æœ‰å…¶ä»–ç±»å‹ï¼Œéœ€ç›¸åº”æ‰©å±•ï¼‰\n\n---\n\n### âœ… SQL æŸ¥è¯¢ï¼ˆé™æ€é€è§†è¡¨æ ¼å¼ï¼‰ï¼š\n\n```sql\nSELECT \n    action_type,\n    AVG(CASE WHEN device_type = 'desktop' THEN duration END) AS avg_duration_desktop,\n    AVG(CASE WHEN device_type = 'mobile' THEN duration END) AS avg_duration_mobile,\n    AVG(CASE WHEN device_type = 'tablet' THEN duration END) AS avg_duration_tablet\nFROM \n    user_interaction_logs\nWHERE \n    duration IS NOT NULL\nGROUP BY \n    action_type\nORDER BY \n    action_type;\n```\n\n---\n\n### è¯´æ˜ï¼š\n- `CASE WHEN device_type = 'xxx' THEN duration END`ï¼šä»…å½“è®¾å¤‡ç±»å‹åŒ¹é…æ—¶æ‰å‚ä¸å¹³å‡è®¡ç®—ï¼Œå¦åˆ™ä¸º NULLï¼Œ`AVG` ä¼šè‡ªåŠ¨å¿½ç•¥ NULLã€‚\n- `GROUP BY action_type`ï¼šæŒ‰æ“ä½œç±»å‹åˆ†ç»„ï¼Œæ¯è¡Œä»£è¡¨ä¸€ç§æ“ä½œç±»å‹ã€‚\n- `ORDER BY action_type`ï¼šä½¿ç»“æœæ›´æ˜“è¯»ã€‚\n- `WHERE duration IS NOT NULL`ï¼šç¡®ä¿è®¡ç®—æ—¶æ’é™¤æ— æ•ˆæ—¶é•¿ã€‚\n\n> ğŸ’¡ å¦‚æœä½ çš„æ•°æ®åº“æ”¯æŒ `PIVOT` è¯­æ³•ï¼ˆå¦‚ SQL Serverã€Oracleï¼‰ï¼Œå¯ä»¥ä½¿ç”¨æ›´ç®€æ´çš„ `PIVOT`ï¼Œä½† MySQL å’Œ PostgreSQL é€šå¸¸ä½¿ç”¨ä¸Šè¿° `CASE` æ–¹æ³•ã€‚æœ¬æŸ¥è¯¢å…¼å®¹ä¸»æµæ•°æ®åº“ï¼ˆMySQLã€PostgreSQLã€SQLiteã€SQL Server ç­‰ï¼‰ã€‚\n\nå¦‚éœ€åŠ¨æ€ç”Ÿæˆåˆ—ï¼ˆæœªçŸ¥è®¾å¤‡ç±»å‹ï¼‰ï¼Œéœ€ä½¿ç”¨åŠ¨æ€ SQLï¼ˆå¦‚å­˜å‚¨è¿‡ç¨‹ï¼‰ï¼Œä½†é€šå¸¸åœ¨æŠ¥è¡¨å±‚å¤„ç†æ›´åˆé€‚ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 79, "group_id": 79, "sample_metadata": {}}}
{"index": 32, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æ‰¾å‡ºè®¢å•é‡‘é¢åœ¨æ‰€åœ¨çŠ¶æ€çš„å¹³å‡é‡‘é¢ä»¥ä¸Šçš„è®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·ã€çŠ¶æ€å’Œé‡‘é¢ã€‚\nSQL:", "target": "SELECT order_id, status, total_amount FROM orders o1 WHERE total_amount > (SELECT AVG(total_amount) FROM orders o2 WHERE o2.status = o1.status);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.30873015873015874}, "extracted_prediction": "SELECT      order_id,     status,     total_amount FROM (     SELECT          order_id,         status,         total_amount,         AVG(total_amount) OVER (PARTITION BY status) AS avg_amount_by_status     FROM orders ) AS ranked_orders WHERE total_amount > avg_amount_by_status", "prediction": "è¦æ‰¾å‡ºè®¢å•é‡‘é¢é«˜äºå…¶æ‰€åœ¨çŠ¶æ€çš„å¹³å‡é‡‘é¢çš„è®¢å•ï¼Œå¹¶æ˜¾ç¤ºè®¢å•å·ï¼ˆ`order_id`ï¼‰ã€çŠ¶æ€ï¼ˆ`status`ï¼‰å’Œé‡‘é¢ï¼ˆ`total_amount`ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨çª—å£å‡½æ•°æˆ–å­æŸ¥è¯¢æ¥è®¡ç®—æ¯ä¸ªçŠ¶æ€çš„å¹³å‡é‡‘é¢ï¼Œç„¶åè¿›è¡Œæ¯”è¾ƒã€‚\n\nä»¥ä¸‹æ˜¯ç¬¦åˆè¦æ±‚çš„ SQL æŸ¥è¯¢ï¼š\n\n```sql\nSELECT \n    order_id,\n    status,\n    total_amount\nFROM (\n    SELECT \n        order_id,\n        status,\n        total_amount,\n        AVG(total_amount) OVER (PARTITION BY status) AS avg_amount_by_status\n    FROM orders\n) AS ranked_orders\nWHERE total_amount > avg_amount_by_status;\n```\n\n### è§£é‡Šï¼š\n1. **å†…å±‚æŸ¥è¯¢**ï¼š\n   - ä½¿ç”¨ `AVG(total_amount) OVER (PARTITION BY status)` è®¡ç®—æ¯ä¸ª `status` åˆ†ç»„çš„å¹³å‡è®¢å•é‡‘é¢ã€‚\n   - åŒæ—¶ä¿ç•™åŸå§‹çš„ `order_id`, `status`, `total_amount`ã€‚\n\n2. **å¤–å±‚æŸ¥è¯¢**ï¼š\n   - ç­›é€‰å‡º `total_amount > avg_amount_by_status` çš„è®¢å•ã€‚\n   - åªé€‰æ‹©éœ€è¦çš„å­—æ®µï¼š`order_id`, `status`, `total_amount`ã€‚\n\nè¿™ä¸ªæŸ¥è¯¢é«˜æ•ˆã€æ¸…æ™°ï¼Œç¬¦åˆç°ä»£ SQL æ ‡å‡†ï¼Œå¹¶èƒ½æ­£ç¡®å¤„ç†é¢˜ç›®è¦æ±‚ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 32, "group_id": 32, "sample_metadata": {}}}
{"index": 18, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢ç”¨æˆ·åä»¥å­—æ¯å¼€å¤´ä¸”é•¿åº¦ä¸º6åˆ°10ä¸ªå­—ç¬¦çš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·åå’Œé‚®ç®±ã€‚\nSQL:", "target": "SELECT username, email FROM users WHERE username GLOB '[a-zA-Z]*' AND LENGTH(username) BETWEEN 6 AND 10;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7333333333333334}, "extracted_prediction": "SELECT username, email FROM users WHERE username REGEXP '^[a-zA-Z][a-zA-Z0-9]{5,9}$'", "prediction": "SELECT username, email\nFROM users\nWHERE username REGEXP '^[a-zA-Z][a-zA-Z0-9]{5,9}$';", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 18, "group_id": 18, "sample_metadata": {}}}
{"index": 45, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æ‰€æœ‰ç ”å‘æ–‡æ¡£ä¸­ï¼Œåˆ›å»ºæ—¶é—´åœ¨2023å¹´ä¸”æ–‡æ¡£å¤§å°è¶…è¿‡1MBçš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜ã€å¤§å°å’Œåˆ›å»ºæ—¶é—´ï¼ŒæŒ‰å¤§å°é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT doc_id, title, file_size, created_date FROM research_docs WHERE strftime('%Y', created_date) = '2023' AND file_size > 1048576 ORDER BY file_size DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8653846153846154}, "extracted_prediction": "SELECT doc_id, title, file_size, created_date FROM research_docs WHERE created_date >= '2023-01-01'    AND created_date < '2024-01-01'   AND file_size > 1048576 ORDER BY file_size DESC", "prediction": "SELECT doc_id, title, file_size, created_date\nFROM research_docs\nWHERE created_date >= '2023-01-01' \n  AND created_date < '2024-01-01'\n  AND file_size > 1048576\nORDER BY file_size DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 45, "group_id": 45, "sample_metadata": {}}}
{"index": 26, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæ”¯ä»˜æ–¹å¼çš„è®¢å•æ•°é‡å’Œæ€»é‡‘é¢ï¼ŒæŒ‰æ€»é‡‘é¢é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT payment_method, COUNT(*) as order_count, SUM(total_amount) as total_amount FROM orders GROUP BY payment_method ORDER BY total_amount DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9545454545454546}, "extracted_prediction": "SELECT      payment_method,     COUNT(order_id) AS order_count,     SUM(total_amount) AS total_amount FROM      orders GROUP BY      payment_method ORDER BY      total_amount DESC", "prediction": "SELECT \n    payment_method,\n    COUNT(order_id) AS order_count,\n    SUM(total_amount) AS total_amount\nFROM \n    orders\nGROUP BY \n    payment_method\nORDER BY \n    total_amount DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 26, "group_id": 26, "sample_metadata": {}}}
{"index": 78, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢æœ€è¿‘24å°æ—¶å†…çš„æ—¥å¿—ï¼Œç»Ÿè®¡æ¯ä¸ªå°æ—¶çš„æ—¥å¿—æ•°é‡ï¼ŒæŒ‰å°æ—¶æ’åºã€‚\nSQL:", "target": "SELECT strftime('%Y-%m-%d %H:00:00', timestamp) as hour, COUNT(*) as count FROM user_interaction_logs WHERE timestamp >= datetime('now', '-24 hours') GROUP BY hour ORDER BY hour;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.6681818181818182}, "extracted_prediction": "SELECT      HOUR(timestamp) AS hour,     COUNT(*) AS log_count FROM      user_interaction_logs WHERE      timestamp >= NOW() - INTERVAL 1 DAY GROUP BY      HOUR(timestamp) ORDER BY      hour", "prediction": "SELECT \n    HOUR(timestamp) AS hour,\n    COUNT(*) AS log_count\nFROM \n    user_interaction_logs\nWHERE \n    timestamp >= NOW() - INTERVAL 1 DAY\nGROUP BY \n    HOUR(timestamp)\nORDER BY \n    hour;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 78, "group_id": 78, "sample_metadata": {}}}
{"index": 44, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æ‰¾å‡ºæ¯ä¸ªæ”¯ä»˜æ–¹å¼ä¸­è®¢å•é‡‘é¢æœ€å¤§çš„è®¢å•ï¼Œæ˜¾ç¤ºæ”¯ä»˜æ–¹å¼ã€è®¢å•å·å’Œé‡‘é¢ã€‚\nSQL:", "target": "SELECT payment_method, order_id, total_amount FROM orders o1 WHERE total_amount = (SELECT MAX(total_amount) FROM orders o2 WHERE o2.payment_method = o1.payment_method);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.203030303030303}, "extracted_prediction": "SELECT payment_method, order_id, total_amount FROM (     SELECT payment_method, order_id, total_amount,            ROW_NUMBER() OVER (PARTITION BY payment_method ORDER BY total_amount DESC) AS rn     FROM orders ) ranked WHERE rn = 1", "prediction": "SELECT payment_method, order_id, total_amount\nFROM (\n    SELECT payment_method, order_id, total_amount,\n           ROW_NUMBER() OVER (PARTITION BY payment_method ORDER BY total_amount DESC) AS rn\n    FROM orders\n) ranked\nWHERE rn = 1;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 44, "group_id": 44, "sample_metadata": {}}}
{"index": 73, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æ‰¾å‡ºæ¯ä¸ªç”¨æˆ·æ“ä½œæ—¶é•¿æœ€é•¿çš„æ—¥å¿—ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€æ—¥å¿—IDã€æ“ä½œç±»å‹å’Œæ—¶é•¿ã€‚\nSQL:", "target": "SELECT user_id, log_id, action_type, duration FROM user_interaction_logs l1 WHERE duration = (SELECT MAX(duration) FROM user_interaction_logs l2 WHERE l2.user_id = l1.user_id);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.43333333333333335}, "extracted_prediction": "SELECT user_id, log_id, action_type, duration FROM user_interaction_logs WHERE (user_id, duration) IN (     SELECT user_id, MAX(duration)     FROM user_interaction_logs     GROUP BY user_id )", "prediction": "SELECT user_id, log_id, action_type, duration\nFROM user_interaction_logs\nWHERE (user_id, duration) IN (\n    SELECT user_id, MAX(duration)\n    FROM user_interaction_logs\n    GROUP BY user_id\n);", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 73, "group_id": 73, "sample_metadata": {}}}
{"index": 1, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªåŸå¸‚çš„ç”¨æˆ·æ•°é‡ï¼Œåªæ˜¾ç¤ºç”¨æˆ·æ•°é‡å¤§äº100çš„åŸå¸‚ï¼ŒæŒ‰ç”¨æˆ·æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT city, COUNT(*) as user_count FROM users GROUP BY city HAVING COUNT(*) > 100 ORDER BY user_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT city, COUNT(*) AS user_count FROM users GROUP BY city HAVING COUNT(*) > 100 ORDER BY user_count DESC", "prediction": "SELECT city, COUNT(*) AS user_count\nFROM users\nGROUP BY city\nHAVING COUNT(*) > 100\nORDER BY user_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 1, "group_id": 1, "sample_metadata": {}}}
{"index": 67, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªè®¾å¤‡ç±»å‹çš„æ—¥å¿—æ•°é‡å’Œå¹³å‡æ“ä½œæ—¶é•¿ï¼ŒæŒ‰æ—¥å¿—æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT device_type, COUNT(*) as log_count, AVG(duration) as avg_duration FROM user_interaction_logs GROUP BY device_type ORDER BY log_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      device_type,     COUNT(*) AS log_count,     AVG(duration) AS avg_duration FROM      user_interaction_logs GROUP BY      device_type ORDER BY      log_count DESC", "prediction": "SELECT \n    device_type,\n    COUNT(*) AS log_count,\n    AVG(duration) AS avg_duration\nFROM \n    user_interaction_logs\nGROUP BY \n    device_type\nORDER BY \n    log_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 67, "group_id": 67, "sample_metadata": {}}}
{"index": 77, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æ‰¾å‡ºæ¯ä¸ªä¼šè¯ä¸­æ“ä½œæ—¶é•¿æœ€é•¿çš„æ—¥å¿—ï¼Œæ˜¾ç¤ºä¼šè¯IDã€æ—¥å¿—IDã€æ“ä½œç±»å‹å’Œæ—¶é•¿ï¼ŒæŒ‰æ—¶é•¿é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT session_id, log_id, action_type, duration FROM user_interaction_logs l1 WHERE duration = (SELECT MAX(duration) FROM user_interaction_logs l2 WHERE l2.session_id = l1.session_id) ORDER BY duration DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.5466666666666666}, "extracted_prediction": "SELECT session_id, log_id, action_type, duration FROM user_interaction_logs WHERE (session_id, duration) IN (     SELECT session_id, MAX(duration)     FROM user_interaction_logs     GROUP BY session_id ) ORDER BY duration DESC", "prediction": "SELECT session_id, log_id, action_type, duration\nFROM user_interaction_logs\nWHERE (session_id, duration) IN (\n    SELECT session_id, MAX(duration)\n    FROM user_interaction_logs\n    GROUP BY session_id\n)\nORDER BY duration DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 77, "group_id": 77, "sample_metadata": {}}}
{"index": 43, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢è®¢å•é‡‘é¢å¤§äºå¹³å‡å€¼ä¸”çŠ¶æ€ä¸ºå·²å®Œæˆçš„è®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·å’Œé‡‘é¢ï¼ŒæŒ‰é‡‘é¢é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT order_id, total_amount FROM orders WHERE total_amount > (SELECT AVG(total_amount) FROM orders) AND status = 'completed' ORDER BY total_amount DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT order_id, total_amount FROM orders WHERE total_amount > (SELECT AVG(total_amount) FROM orders)   AND status = 'å·²å®Œæˆ' ORDER BY total_amount DESC", "prediction": "SELECT order_id, total_amount\nFROM orders\nWHERE total_amount > (SELECT AVG(total_amount) FROM orders)\n  AND status = 'å·²å®Œæˆ'\nORDER BY total_amount DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 43, "group_id": 43, "sample_metadata": {}}}
{"index": 15, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºå¹´é¾„åœ¨æ‰€åœ¨åŸå¸‚å¹³å‡å¹´é¾„ä»¥ä¸Šçš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åã€åŸå¸‚å’Œå¹´é¾„ã€‚\nSQL:", "target": "SELECT user_id, username, city, age FROM users u1 WHERE age > (SELECT AVG(age) FROM users u2 WHERE u2.city = u1.city);", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      user_id,     username,     city,     age FROM      users u1 WHERE      age > (         SELECT AVG(age)         FROM users u2         WHERE u2.city = u1.city     )", "prediction": "è¦æ‰¾å‡ºå¹´é¾„é«˜äºå…¶æ‰€åœ¨åŸå¸‚å¹³å‡å¹´é¾„çš„ç”¨æˆ·ï¼Œæˆ‘ä»¬éœ€è¦ï¼š\n\n1. è®¡ç®—æ¯ä¸ªåŸå¸‚çš„å¹³å‡å¹´é¾„ï¼›\n2. å°†æ¯ä¸ªç”¨æˆ·ä¸å…¶æ‰€åœ¨åŸå¸‚çš„å¹³å‡å¹´é¾„è¿›è¡Œæ¯”è¾ƒï¼›\n3. ç­›é€‰å‡ºå¹´é¾„å¤§äºè¯¥åŸå¸‚å¹³å‡å¹´é¾„çš„ç”¨æˆ·ï¼›\n4. è¿”å›ç”¨æˆ·IDã€ç”¨æˆ·åã€åŸå¸‚å’Œå¹´é¾„ã€‚\n\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨**çª—å£å‡½æ•°**æˆ–**å­æŸ¥è¯¢**æ¥å®ç°ã€‚è¿™é‡Œä½¿ç”¨å­æŸ¥è¯¢æ–¹å¼ï¼Œé€»è¾‘æ¸…æ™°ä¸”å…¼å®¹æ€§å¥½ã€‚\n\n### SQL æŸ¥è¯¢ï¼š\n\n```sql\nSELECT \n    user_id,\n    username,\n    city,\n    age\nFROM \n    users u1\nWHERE \n    age > (\n        SELECT AVG(age)\n        FROM users u2\n        WHERE u2.city = u1.city\n    );\n```\n\n### è¯´æ˜ï¼š\n- å¤–å±‚æŸ¥è¯¢ï¼šé€‰æ‹©ç”¨æˆ·ä¿¡æ¯ï¼ˆuser_id, username, city, ageï¼‰ã€‚\n- å­æŸ¥è¯¢ï¼šå¯¹æ¯ä¸ªç”¨æˆ· `u1`ï¼Œè®¡ç®—å…¶æ‰€åœ¨åŸå¸‚ `u1.city` çš„å¹³å‡å¹´é¾„ã€‚\n- `WHERE age > (...)`ï¼šåªä¿ç•™å¹´é¾„é«˜äºè¯¥åŸå¸‚å¹³å‡å¹´é¾„çš„ç”¨æˆ·ã€‚\n\nè¿™ä¸ªæŸ¥è¯¢æ»¡è¶³é¢˜ç›®è¦æ±‚ï¼Œè¿”å›ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·IDã€ç”¨æˆ·åã€åŸå¸‚å’Œå¹´é¾„ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 15, "group_id": 15, "sample_metadata": {}}}
{"index": 76, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢æ“ä½œç±»å‹ä¸º'click'æˆ–'view'çš„æ—¥å¿—ï¼ŒæŒ‰è®¾å¤‡ç±»å‹ç»Ÿè®¡æ•°é‡å’Œå¹³å‡æ—¶é•¿ï¼ŒæŒ‰æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT device_type, COUNT(*) as count, AVG(duration) as avg_duration FROM user_interaction_logs WHERE action_type IN ('click', 'view') GROUP BY device_type ORDER BY count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      device_type,     COUNT(*) AS count,     AVG(duration) AS avg_duration FROM      user_interaction_logs WHERE      action_type IN ('click', 'view') GROUP BY      device_type ORDER BY      count DESC", "prediction": "SELECT \n    device_type,\n    COUNT(*) AS count,\n    AVG(duration) AS avg_duration\nFROM \n    user_interaction_logs\nWHERE \n    action_type IN ('click', 'view')\nGROUP BY \n    device_type\nORDER BY \n    count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 76, "group_id": 76, "sample_metadata": {}}}
{"index": 42, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„æ€»è®¢å•æ•°ã€æ€»è®¢å•é‡‘é¢å’Œå¹³å‡è®¢å•é‡‘é¢ï¼Œåªæ˜¾ç¤ºè®¢å•æ•°å¤§äº5çš„ç”¨æˆ·ï¼ŒæŒ‰æ€»é‡‘é¢é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT user_id, COUNT(*) as order_count, SUM(total_amount) as total_amount, AVG(total_amount) as avg_amount FROM orders GROUP BY user_id HAVING COUNT(*) > 5 ORDER BY total_amount DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8628571428571428}, "extracted_prediction": "SELECT      user_id,     COUNT(order_id) AS total_orders,     SUM(total_amount) AS total_amount,     AVG(total_amount) AS average_amount FROM      orders GROUP BY      user_id HAVING      COUNT(order_id) > 5 ORDER BY      total_amount DESC", "prediction": "SELECT \n    user_id,\n    COUNT(order_id) AS total_orders,\n    SUM(total_amount) AS total_amount,\n    AVG(total_amount) AS average_amount\nFROM \n    orders\nGROUP BY \n    user_id\nHAVING \n    COUNT(order_id) > 5\nORDER BY \n    total_amount DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 42, "group_id": 42, "sample_metadata": {}}}
{"index": 59, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æè¿°é•¿åº¦å¤§äº100ä¸ªå­—ç¬¦çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜å’Œæè¿°é•¿åº¦ï¼ŒæŒ‰æè¿°é•¿åº¦é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT doc_id, title, LENGTH(description) as desc_length FROM research_docs WHERE LENGTH(description) > 100 ORDER BY desc_length DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7833333333333333}, "extracted_prediction": "SELECT doc_id, title, LENGTH(description) AS description_length FROM research_docs WHERE LENGTH(description) > 100 ORDER BY description_length DESC", "prediction": "SELECT doc_id, title, LENGTH(description) AS description_length\nFROM research_docs\nWHERE LENGTH(description) > 100\nORDER BY description_length DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 59, "group_id": 59, "sample_metadata": {}}}
{"index": 17, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæ€§åˆ«åœ¨ä¸åŒåŸå¸‚çš„åˆ†å¸ƒæƒ…å†µï¼Œæ˜¾ç¤ºæ€§åˆ«ã€åŸå¸‚å’Œç”¨æˆ·æ•°é‡ï¼ŒæŒ‰æ€§åˆ«å’Œç”¨æˆ·æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT gender, city, COUNT(*) as count FROM users GROUP BY gender, city ORDER BY gender, count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8722222222222222}, "extracted_prediction": "SELECT      gender,      city,      COUNT(*) AS user_count FROM      users GROUP BY      gender,      city ORDER BY      gender DESC,      user_count DESC", "prediction": "SELECT \n    gender, \n    city, \n    COUNT(*) AS user_count\nFROM \n    users\nGROUP BY \n    gender, \n    city\nORDER BY \n    gender DESC, \n    user_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 17, "group_id": 17, "sample_metadata": {}}}
{"index": 61, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢åˆ›å»ºæ—¶é—´åœ¨å‘¨æœ«çš„æ–‡æ¡£ï¼Œç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ–‡æ¡£æ•°é‡ã€‚\nSQL:", "target": "SELECT category, COUNT(*) as count FROM research_docs WHERE strftime('%w', created_date) IN ('0', '6') GROUP BY category;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8778409090909091}, "extracted_prediction": "SELECT      category,      COUNT(*) AS document_count FROM      research_docs WHERE      strftime('%w', created_date) IN ('0', '6')  -- 0 = Sunday, 6 = Saturday GROUP BY      category", "prediction": "SELECT \n    category, \n    COUNT(*) AS document_count\nFROM \n    research_docs\nWHERE \n    strftime('%w', created_date) IN ('0', '6')  -- 0 = Sunday, 6 = Saturday\nGROUP BY \n    category;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 61, "group_id": 61, "sample_metadata": {}}}
{"index": 64, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæ“ä½œç±»å‹ï¼ˆaction_typeï¼‰çš„æ—¥å¿—æ•°é‡å’Œå¹³å‡æ“ä½œæ—¶é•¿ï¼ŒæŒ‰æ—¥å¿—æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT action_type, COUNT(*) as log_count, AVG(duration) as avg_duration FROM user_interaction_logs GROUP BY action_type ORDER BY log_count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      action_type,      COUNT(*) AS log_count,      AVG(duration) AS avg_duration FROM      user_interaction_logs GROUP BY      action_type ORDER BY      log_count DESC", "prediction": "SELECT \n    action_type, \n    COUNT(*) AS log_count, \n    AVG(duration) AS avg_duration\nFROM \n    user_interaction_logs\nGROUP BY \n    action_type\nORDER BY \n    log_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 64, "group_id": 64, "sample_metadata": {}}}
{"index": 28, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æ‰¾å‡ºæŠ˜æ‰£é‡‘é¢æœ€é«˜çš„å‰10ä¸ªè®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·ã€æ€»é‡‘é¢ã€æŠ˜æ‰£é‡‘é¢å’Œå®é™…æ”¯ä»˜é‡‘é¢ã€‚\nSQL:", "target": "SELECT order_id, total_amount, discount, (total_amount - discount + tax) as final_amount FROM orders ORDER BY discount DESC LIMIT 10;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.95}, "extracted_prediction": "SELECT      order_id,      total_amount,      discount,      (total_amount - discount + tax) AS actual_payment_amount FROM      orders ORDER BY      discount DESC LIMIT 10", "prediction": "SELECT \n    order_id, \n    total_amount, \n    discount, \n    (total_amount - discount + tax) AS actual_payment_amount\nFROM \n    orders\nORDER BY \n    discount DESC\nLIMIT 10;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 28, "group_id": 28, "sample_metadata": {}}}
{"index": 41, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢2023å¹´12æœˆçš„è®¢å•ï¼ŒæŒ‰æ—¥æœŸç»Ÿè®¡æ¯å¤©çš„è®¢å•æ•°é‡å’Œæ€»é‡‘é¢ï¼Œåªæ˜¾ç¤ºè®¢å•æ•°é‡è¶…è¿‡10çš„æ—¥æœŸã€‚\nSQL:", "target": "SELECT order_date, COUNT(*) as count, SUM(total_amount) as total FROM orders WHERE strftime('%Y-%m', order_date) = '2023-12' GROUP BY order_date HAVING COUNT(*) > 10 ORDER BY order_date;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8363636363636364}, "extracted_prediction": "SELECT      order_date,     COUNT(*) AS order_count,     SUM(total_amount) AS total_amount FROM      orders WHERE      order_date >= '2023-12-01'      AND order_date < '2024-01-01' GROUP BY      order_date HAVING      COUNT(*) > 10 ORDER BY      order_date", "prediction": "SELECT \n    order_date,\n    COUNT(*) AS order_count,\n    SUM(total_amount) AS total_amount\nFROM \n    orders\nWHERE \n    order_date >= '2023-12-01' \n    AND order_date < '2024-01-01'\nGROUP BY \n    order_date\nHAVING \n    COUNT(*) > 10\nORDER BY \n    order_date;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 41, "group_id": 41, "sample_metadata": {}}}
{"index": 58, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æ‰¾å‡ºæ¯ä¸ªä½œè€…åœ¨2023å¹´åˆ›å»ºçš„æ–‡æ¡£æ€»å¤§å°ï¼Œåªæ˜¾ç¤ºæ€»å¤§å°è¶…è¿‡50MBçš„ä½œè€…ï¼ŒæŒ‰æ€»å¤§å°é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT author, SUM(file_size) as total_size FROM research_docs WHERE strftime('%Y', created_date) = '2023' GROUP BY author HAVING SUM(file_size) > 52428800 ORDER BY total_size DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8666666666666667}, "extracted_prediction": "SELECT      author,      SUM(file_size) AS total_size FROM      research_docs WHERE      created_date >= '2023-01-01'      AND created_date <= '2023-12-31' GROUP BY      author HAVING      SUM(file_size) > 50 ORDER BY      total_size DESC", "prediction": "SELECT \n    author, \n    SUM(file_size) AS total_size\nFROM \n    research_docs\nWHERE \n    created_date >= '2023-01-01' \n    AND created_date <= '2023-12-31'\nGROUP BY \n    author\nHAVING \n    SUM(file_size) > 50\nORDER BY \n    total_size DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 58, "group_id": 58, "sample_metadata": {}}}
{"index": 29, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢çŠ¶æ€ä¸ºå·²å®Œæˆä¸”è®¢å•é‡‘é¢åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„è®¢å•æ•°é‡ï¼ŒæŒ‰ç”¨æˆ·IDåˆ†ç»„ç»Ÿè®¡ã€‚\nSQL:", "target": "SELECT user_id, COUNT(*) as count FROM orders WHERE status = 'completed' AND total_amount > (SELECT AVG(total_amount) FROM orders) GROUP BY user_id;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.975}, "extracted_prediction": "SELECT      user_id,     COUNT(*) AS order_count FROM      orders WHERE      status = 'completed'     AND total_amount > (SELECT AVG(total_amount) FROM orders) GROUP BY      user_id", "prediction": "è¦å°†é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ï¼š\n\n1. **ç­›é€‰æ¡ä»¶**ï¼šçŠ¶æ€ä¸ºâ€œå·²å®Œæˆâ€ï¼ˆ`status = 'completed'`ï¼‰ï¼Œä¸”è®¢å•é‡‘é¢ï¼ˆ`total_amount`ï¼‰**é«˜äºæ‰€æœ‰è®¢å•çš„å¹³å‡å€¼**ã€‚\n2. **åˆ†ç»„ç»Ÿè®¡**ï¼šæŒ‰ `user_id` åˆ†ç»„ï¼Œç»Ÿè®¡æ»¡è¶³æ¡ä»¶çš„è®¢å•æ•°é‡ã€‚\n3. **è®¡ç®—å¹³å‡å€¼**ï¼šä½¿ç”¨å­æŸ¥è¯¢è®¡ç®— `total_amount` çš„å¹³å‡å€¼ã€‚\n\n### SQL æŸ¥è¯¢å¦‚ä¸‹ï¼š\n\n```sql\nSELECT \n    user_id,\n    COUNT(*) AS order_count\nFROM \n    orders\nWHERE \n    status = 'completed'\n    AND total_amount > (SELECT AVG(total_amount) FROM orders)\nGROUP BY \n    user_id;\n```\n\n### è¯´æ˜ï¼š\n- `status = 'completed'`ï¼šç­›é€‰å·²å®Œæˆçš„è®¢å•ã€‚\n- `total_amount > (SELECT AVG(total_amount) FROM orders)`ï¼šç­›é€‰é‡‘é¢é«˜äºå¹³å‡å€¼çš„è®¢å•ã€‚\n- `GROUP BY user_id`ï¼šæŒ‰ç”¨æˆ·åˆ†ç»„ã€‚\n- `COUNT(*)`ï¼šç»Ÿè®¡æ¯ä¸ªç”¨æˆ·æ»¡è¶³æ¡ä»¶çš„è®¢å•æ•°é‡ã€‚\n\n> æ³¨æ„ï¼šå‡è®¾â€œå·²å®Œæˆâ€çš„çŠ¶æ€å­—æ®µå€¼ä¸º `'completed'`ï¼Œå¦‚æœå®é™…æ•°æ®åº“ä¸­æ˜¯å…¶ä»–å€¼ï¼ˆå¦‚ `'finished'` æˆ– `'completed'` çš„ä¸­æ–‡ï¼‰ï¼Œè¯·æ ¹æ®å®é™…æ•°æ®è°ƒæ•´ã€‚å½“å‰æŒ‰è‹±æ–‡æ ‡å‡†å€¼å¤„ç†ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 29, "group_id": 29, "sample_metadata": {}}}
{"index": 11, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºæ³¨å†Œæ—¶é—´åœ¨å‘¨æœ«ï¼ˆå‘¨å…­æˆ–å‘¨æ—¥ï¼‰çš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·åã€æ³¨å†Œæ—¥æœŸå’Œæ˜ŸæœŸå‡ ã€‚\nSQL:", "target": "SELECT username, registration_date, CASE CAST(strftime('%w', registration_date) AS INTEGER) WHEN 0 THEN 'Sunday' WHEN 6 THEN 'Saturday' END as day_of_week FROM users WHERE strftime('%w', registration_date) IN ('0', '6');", "sample_score": {"score": {"value": {"sql_ast_sim": 0.823529411764706}, "extracted_prediction": "SELECT      username,      registration_date,      strftime('%w', registration_date) AS weekday FROM      users WHERE      strftime('%w', registration_date) IN ('0', '6')", "prediction": "SELECT \n    username, \n    registration_date, \n    strftime('%w', registration_date) AS weekday\nFROM \n    users\nWHERE \n    strftime('%w', registration_date) IN ('0', '6');", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 11, "group_id": 11, "sample_metadata": {}}}
{"index": 40, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æ‰¾å‡ºç¨è´¹é‡‘é¢æœ€é«˜çš„å‰5ä¸ªè®¢å•ï¼Œæ˜¾ç¤ºè®¢å•å·ã€æ€»é‡‘é¢ã€ç¨è´¹å’Œç¨è´¹å æ¯”ã€‚\nSQL:", "target": "SELECT order_id, total_amount, tax, ROUND(tax * 100.0 / total_amount, 2) as tax_rate FROM orders ORDER BY tax DESC LIMIT 5;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.75}, "extracted_prediction": "SELECT      order_id,     total_amount,     tax,     (tax / total_amount) * 100 AS tax_percentage FROM      orders WHERE      total_amount > 0  -- é¿å…é™¤ä»¥é›¶ ORDER BY      tax DESC LIMIT 5", "prediction": "SELECT \n    order_id,\n    total_amount,\n    tax,\n    (tax / total_amount) * 100 AS tax_percentage\nFROM \n    orders\nWHERE \n    total_amount > 0  -- é¿å…é™¤ä»¥é›¶\nORDER BY \n    tax DESC\nLIMIT 5;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 40, "group_id": 40, "sample_metadata": {}}}
{"index": 57, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æ–‡ä»¶å¤§å°åœ¨1MBåˆ°10MBä¹‹é—´çš„æ–‡æ¡£ï¼ŒæŒ‰ç±»åˆ«ç»Ÿè®¡æ•°é‡å’Œæ€»å¤§å°ï¼ŒæŒ‰æ€»å¤§å°é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT category, COUNT(*) as count, SUM(file_size) as total_size FROM research_docs WHERE file_size BETWEEN 1048576 AND 10485760 GROUP BY category ORDER BY total_size DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8818181818181818}, "extracted_prediction": "SELECT      category,     COUNT(*) AS document_count,     SUM(file_size) AS total_size FROM      research_docs WHERE      file_size BETWEEN 1048576 AND 10485760  -- 1MB = 1048576 bytes, 10MB = 10485760 bytes GROUP BY      category ORDER BY      total_size DESC", "prediction": "SELECT \n    category,\n    COUNT(*) AS document_count,\n    SUM(file_size) AS total_size\nFROM \n    research_docs\nWHERE \n    file_size BETWEEN 1048576 AND 10485760  -- 1MB = 1048576 bytes, 10MB = 10485760 bytes\nGROUP BY \n    category\nORDER BY \n    total_size DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 57, "group_id": 57, "sample_metadata": {}}}
{"index": 10, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢æ‰‹æœºå·ä»¥138å¼€å¤´çš„ç”¨æˆ·ä¸­ï¼Œå¹´é¾„æœ€å¤§çš„å‰3åç”¨æˆ·ä¿¡æ¯ã€‚\nSQL:", "target": "SELECT * FROM users WHERE phone LIKE '138%' ORDER BY age DESC LIMIT 3;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT * FROM users WHERE phone LIKE '138%' ORDER BY age DESC LIMIT 3", "prediction": "SELECT *\nFROM users\nWHERE phone LIKE '138%'\nORDER BY age DESC\nLIMIT 3;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 10, "group_id": 10, "sample_metadata": {}}}
{"index": 62, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æ‰¾å‡ºæ ‡é¢˜é•¿åº¦å¤§äº30ä¸ªå­—ç¬¦ä¸”æ–‡ä»¶å¤§å°å°äº500KBçš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜å’Œæ–‡ä»¶å¤§å°ã€‚\nSQL:", "target": "SELECT doc_id, title, file_size FROM research_docs WHERE LENGTH(title) > 30 AND file_size < 512000 ORDER BY file_size ASC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.75}, "extracted_prediction": "SELECT doc_id, title, file_size FROM research_docs WHERE LENGTH(title) > 30 AND file_size < 500", "prediction": "SELECT doc_id, title, file_size\nFROM research_docs\nWHERE LENGTH(title) > 30 AND file_size < 500;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 62, "group_id": 62, "sample_metadata": {}}}
{"index": 9, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªçŠ¶æ€ï¼ˆstatusï¼‰çš„ç”¨æˆ·æ•°é‡ï¼Œå¹¶è®¡ç®—å„çŠ¶æ€ç”¨æˆ·å æ€»ç”¨æˆ·æ•°çš„ç™¾åˆ†æ¯”ã€‚\nSQL:", "target": "SELECT status, COUNT(*) as count, ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM users), 2) as percentage FROM users GROUP BY status;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.725}, "extracted_prediction": "SELECT      status,     COUNT(*) AS user_count,     ROUND(         COUNT(*) * 100.0 / (SELECT COUNT(*) FROM users),          2     ) AS percentage FROM      users GROUP BY      status ORDER BY      status", "prediction": "SELECT \n    status,\n    COUNT(*) AS user_count,\n    ROUND(\n        COUNT(*) * 100.0 / (SELECT COUNT(*) FROM users), \n        2\n    ) AS percentage\nFROM \n    users\nGROUP BY \n    status\nORDER BY \n    status;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 9, "group_id": 9, "sample_metadata": {}}}
{"index": 14, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢é‚®ç®±åœ°å€ä¸­åŒ…å«å…¬å¸åŸŸåï¼ˆåŒ…å«'company'æˆ–'corp'ï¼‰çš„ç”¨æˆ·ï¼ŒæŒ‰æ³¨å†Œæ—¶é—´å‡åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT * FROM users WHERE email LIKE '%company%' OR email LIKE '%corp%' ORDER BY registration_date ASC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT * FROM users WHERE email LIKE '%company%' OR email LIKE '%corp%' ORDER BY registration_date ASC", "prediction": "SELECT *\nFROM users\nWHERE email LIKE '%company%' OR email LIKE '%corp%'\nORDER BY registration_date ASC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 14, "group_id": 14, "sample_metadata": {}}}
{"index": 8, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºæ³¨å†Œè¶…è¿‡1å¹´ä½†ä»æœªç™»å½•è¿‡çš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åå’Œæ³¨å†Œæ—¥æœŸã€‚\nSQL:", "target": "SELECT user_id, username, registration_date FROM users WHERE registration_date < DATE('now', '-1 year') AND (last_login_date IS NULL OR last_login_date = registration_date);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9047619047619048}, "extracted_prediction": "SELECT user_id, username, registration_date FROM users WHERE registration_date <= DATE('now', '-1 year')   AND last_login_date IS NULL", "prediction": "SELECT user_id, username, registration_date\nFROM users\nWHERE registration_date <= DATE('now', '-1 year')\n  AND last_login_date IS NULL;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 8, "group_id": 8, "sample_metadata": {}}}
{"index": 30, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: ç»Ÿè®¡æ¯ä¸ªçŠ¶æ€çš„è®¢å•æ•°é‡å’Œå¹³å‡è®¢å•é‡‘é¢ï¼ŒæŒ‰è®¢å•æ•°é‡é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT status, COUNT(*) as count, AVG(total_amount) as avg_amount FROM orders GROUP BY status ORDER BY count DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7708333333333334}, "extracted_prediction": "SELECT      status,      COUNT(*) AS order_count,      AVG(total_amount) AS average_order_amount FROM      orders GROUP BY      status ORDER BY      order_count DESC", "prediction": "SELECT \n    status, \n    COUNT(*) AS order_count, \n    AVG(total_amount) AS average_order_amount\nFROM \n    orders\nGROUP BY \n    status\nORDER BY \n    order_count DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 30, "group_id": 30, "sample_metadata": {}}}
{"index": 56, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªç±»åˆ«ä¸­ä¸åŒçŠ¶æ€çš„æ–‡æ¡£æ•°é‡ï¼Œä½¿ç”¨é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºã€‚\nSQL:", "target": "SELECT category, SUM(CASE WHEN status = 'draft' THEN 1 ELSE 0 END) as draft_count, SUM(CASE WHEN status = 'published' THEN 1 ELSE 0 END) as published_count, SUM(CASE WHEN status = 'archived' THEN 1 ELSE 0 END) as archived_count FROM research_docs GROUP BY category;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.65}, "extracted_prediction": "SELECT      category,     SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,     SUM(CASE WHEN status = 'draft' THEN 1 ELSE 0 END) AS draft,     SUM(CASE WHEN status = 'archived' THEN 1 ELSE 0 END) AS archived,     SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) AS pending,     COUNT(*) AS total FROM research_docs GROUP BY category ORDER BY category", "prediction": "è¦å°†é—®é¢˜â€œç»Ÿè®¡æ¯ä¸ªç±»åˆ«ä¸­ä¸åŒçŠ¶æ€çš„æ–‡æ¡£æ•°é‡ï¼Œä½¿ç”¨é€è§†è¡¨æ ¼å¼æ˜¾ç¤ºâ€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ï¼š\n\n- æŒ‰ `category` åˆ†ç»„ï¼›\n- ç»Ÿè®¡æ¯ä¸ªç±»åˆ«ä¸­æ¯ç§ `status` çš„æ–‡æ¡£æ•°é‡ï¼›\n- ä½¿ç”¨**é€è§†è¡¨ï¼ˆPivotï¼‰**æ ¼å¼æ˜¾ç¤ºï¼Œå³æ¯ä¸ª `status` ä½œä¸ºä¸€åˆ—ï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ª `category`ï¼Œå•å…ƒæ ¼ä¸ºå¯¹åº”çŠ¶æ€çš„æ–‡æ¡£æ•°é‡ã€‚\n\nç”±äºæ ‡å‡† SQL ä¸ç›´æ¥æ”¯æŒ `PIVOT`ï¼ˆMySQL ä¸æ”¯æŒï¼Œä½† PostgreSQLã€SQL Serverã€Oracle æ”¯æŒï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨**æ¡ä»¶èšåˆï¼ˆConditional Aggregationï¼‰**æ¥æ¨¡æ‹Ÿé€è§†è¡¨ï¼Œè¿™æ˜¯æœ€é€šç”¨ä¸”å…¼å®¹æ€§æœ€å¥½çš„æ–¹æ³•ã€‚\n\nå‡è®¾ `status` çš„å¯èƒ½å€¼åŒ…æ‹¬ï¼š`'active'`, `'draft'`, `'archived'`, `'pending'`ï¼ˆæ ¹æ®å®é™…æ•°æ®å¯è°ƒæ•´ï¼‰ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªçŠ¶æ€åˆ›å»ºä¸€åˆ—ã€‚\n\n### âœ… SQL æŸ¥è¯¢ï¼ˆä½¿ç”¨æ¡ä»¶èšåˆæ¨¡æ‹Ÿé€è§†è¡¨ï¼‰ï¼š\n\n```sql\nSELECT \n    category,\n    SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,\n    SUM(CASE WHEN status = 'draft' THEN 1 ELSE 0 END) AS draft,\n    SUM(CASE WHEN status = 'archived' THEN 1 ELSE 0 END) AS archived,\n    SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) AS pending,\n    COUNT(*) AS total\nFROM research_docs\nGROUP BY category\nORDER BY category;\n```\n\n### ğŸ” è¯´æ˜ï¼š\n- `SUM(CASE WHEN status = 'xxx' THEN 1 ELSE 0 END)`ï¼šå¯¹æ¯ä¸ªçŠ¶æ€è¿›è¡Œè®¡æ•°ï¼›\n- `GROUP BY category`ï¼šæŒ‰ç±»åˆ«åˆ†ç»„ï¼›\n- `COUNT(*) AS total`ï¼šå¯é€‰ï¼Œæ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„æ€»æ–‡æ¡£æ•°ï¼›\n- `ORDER BY category`ï¼šæŒ‰ç±»åˆ«æ’åºï¼Œä¾¿äºé˜…è¯»ã€‚\n\n### ğŸ“Œ æ³¨æ„ï¼š\nå¦‚æœ `status` çš„å–å€¼æœªçŸ¥æˆ–åŠ¨æ€å˜åŒ–ï¼Œä½ éœ€è¦å…ˆæŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„ `status` å€¼ï¼Œç„¶ååŠ¨æ€ç”Ÿæˆ SQLï¼ˆå¦‚åœ¨åº”ç”¨å±‚æˆ–å­˜å‚¨è¿‡ç¨‹ä¸­ï¼‰ã€‚ä½†åœ¨é™æ€æŸ¥è¯¢ä¸­ï¼Œæ‰‹åŠ¨åˆ—å‡ºå·²çŸ¥çŠ¶æ€æ˜¯æ ‡å‡†åšæ³•ã€‚\n\nå¦‚æœä½ çš„æ•°æ®åº“æ”¯æŒ `PIVOT`ï¼ˆå¦‚ SQL Serverï¼‰ï¼Œè¯­æ³•ä¼šæ›´ç®€æ´ï¼Œä½†ä¸Šè¿°å†™æ³•å…¼å®¹ MySQLã€PostgreSQLã€SQLiteã€Oracle ç­‰ä¸»æµæ•°æ®åº“ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 56, "group_id": 56, "sample_metadata": {}}}
{"index": 66, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æ‰¾å‡ºæ¯ä¸ªä¼šè¯ï¼ˆsession_idï¼‰ä¸­çš„æ“ä½œæ¬¡æ•°å’Œæ€»æ—¶é•¿ï¼Œåªæ˜¾ç¤ºæ“ä½œæ¬¡æ•°å¤§äº10çš„ä¼šè¯ï¼ŒæŒ‰æ€»æ—¶é•¿é™åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT session_id, COUNT(*) as action_count, SUM(duration) as total_duration FROM user_interaction_logs GROUP BY session_id HAVING COUNT(*) > 10 ORDER BY total_duration DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      session_id,      COUNT(*) AS action_count,      SUM(duration) AS total_duration FROM      user_interaction_logs GROUP BY      session_id HAVING      COUNT(*) > 10 ORDER BY      total_duration DESC", "prediction": "SELECT \n    session_id, \n    COUNT(*) AS action_count, \n    SUM(duration) AS total_duration\nFROM \n    user_interaction_logs\nGROUP BY \n    session_id\nHAVING \n    COUNT(*) > 10\nORDER BY \n    total_duration DESC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 66, "group_id": 66, "sample_metadata": {}}}
{"index": 65, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢çŠ¶æ€ç ä¸º200ä¸”æ“ä½œæ—¶é•¿è¶…è¿‡5ç§’çš„æ—¥å¿—ï¼Œæ˜¾ç¤ºæ—¥å¿—IDã€ç”¨æˆ·IDã€æ“ä½œç±»å‹å’Œæ—¶é•¿ï¼ŒæŒ‰æ—¶é•¿é™åºæ’åˆ—ï¼Œæ˜¾ç¤ºå‰100æ¡ã€‚\nSQL:", "target": "SELECT log_id, user_id, action_type, duration FROM user_interaction_logs WHERE status_code = 200 AND duration > 5 ORDER BY duration DESC LIMIT 100;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT log_id, user_id, action_type, duration FROM user_interaction_logs WHERE status_code = 200 AND duration > 5 ORDER BY duration DESC LIMIT 100", "prediction": "SELECT log_id, user_id, action_type, duration\nFROM user_interaction_logs\nWHERE status_code = 200 AND duration > 5\nORDER BY duration DESC\nLIMIT 100;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 65, "group_id": 65, "sample_metadata": {}}}
{"index": 38, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæ”¯ä»˜æ–¹å¼åœ¨ä¸åŒçŠ¶æ€ä¸‹çš„è®¢å•æ•°é‡ï¼Œä½¿ç”¨äº¤å‰è¡¨æ ¼å¼æ˜¾ç¤ºã€‚\nSQL:", "target": "SELECT payment_method, SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) as pending_count, SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_count, SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) as cancelled_count FROM orders GROUP BY payment_method;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.65}, "extracted_prediction": "SELECT      payment_method,     SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) AS pending,     SUM(CASE WHEN status = 'shipped' THEN 1 ELSE 0 END) AS shipped,     SUM(CASE WHEN status = 'delivered' THEN 1 ELSE 0 END) AS delivered,     SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) AS cancelled,     COUNT(*) AS total FROM orders GROUP BY payment_method ORDER BY payment_method", "prediction": "è¦å°†é—®é¢˜â€œç»Ÿè®¡æ¯ä¸ªæ”¯ä»˜æ–¹å¼åœ¨ä¸åŒçŠ¶æ€ä¸‹çš„è®¢å•æ•°é‡ï¼Œä½¿ç”¨äº¤å‰è¡¨æ ¼å¼æ˜¾ç¤ºâ€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ **æ¡ä»¶èšåˆï¼ˆConditional Aggregationï¼‰** æˆ– **PIVOT**ï¼ˆå¦‚æœæ•°æ®åº“æ”¯æŒï¼‰æ¥ç”Ÿæˆäº¤å‰è¡¨ï¼ˆå³è¡Œæ˜¯æ”¯ä»˜æ–¹å¼ï¼Œåˆ—æ˜¯çŠ¶æ€ï¼Œå•å…ƒæ ¼æ˜¯è®¢å•æ•°é‡ï¼‰ã€‚\n\nç”±äºæ ‡å‡† SQL æ²¡æœ‰ `PIVOT` è¯­æ³•ï¼ˆMySQL ä¸æ”¯æŒï¼ŒPostgreSQL å’Œ SQL Server æ”¯æŒï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨é€šç”¨çš„ **CASE + SUM** æ–¹æ³•å®ç°äº¤å‰è¡¨ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ•°æ®åº“ï¼ˆå¦‚ MySQLã€PostgreSQLã€SQLite ç­‰ï¼‰ã€‚\n\n### å‡è®¾ï¼š\n- `payment_method` å­—æ®µåŒ…å«å¦‚ï¼š'credit_card', 'paypal', 'wechat', 'alipay' ç­‰å€¼ã€‚\n- `status` å­—æ®µåŒ…å«å¦‚ï¼š'pending', 'shipped', 'delivered', 'cancelled' ç­‰å€¼ã€‚\n\næˆ‘ä»¬åŠ¨æ€åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„ `status` å€¼ï¼ˆæ ¹æ®å®é™…æ•°æ®è°ƒæ•´ï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸ªçŠ¶æ€åˆ›å»ºä¸€åˆ—ã€‚\n\n### SQL æŸ¥è¯¢ï¼ˆäº¤å‰è¡¨æ ¼å¼ï¼‰ï¼š\n```sql\nSELECT \n    payment_method,\n    SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) AS pending,\n    SUM(CASE WHEN status = 'shipped' THEN 1 ELSE 0 END) AS shipped,\n    SUM(CASE WHEN status = 'delivered' THEN 1 ELSE 0 END) AS delivered,\n    SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) AS cancelled,\n    COUNT(*) AS total\nFROM orders\nGROUP BY payment_method\nORDER BY payment_method;\n```\n\n### è¯´æ˜ï¼š\n- æ¯ä¸ª `CASE WHEN status = 'xxx' THEN 1 ELSE 0 END` ç»Ÿè®¡å¯¹åº”çŠ¶æ€çš„è®¢å•æ•°ã€‚\n- `SUM(...)` å¯¹æ¯ä¸ªæ”¯ä»˜æ–¹å¼ä¸‹çš„å„çŠ¶æ€è®¢å•è¿›è¡Œè®¡æ•°ã€‚\n- `COUNT(*)` ä½œä¸ºæ€»è®¢å•æ•°çš„è¾…åŠ©å‚è€ƒï¼ˆå¯é€‰ï¼‰ã€‚\n- `GROUP BY payment_method` æŒ‰æ”¯ä»˜æ–¹å¼åˆ†ç»„ã€‚\n- ç»“æœä»¥â€œæ”¯ä»˜æ–¹å¼â€ä¸ºè¡Œï¼Œâ€œçŠ¶æ€â€ä¸ºåˆ—ï¼Œå½¢æˆäº¤å‰è¡¨ã€‚\n\n### æ³¨æ„ï¼š\nå¦‚æœå®é™…æ•°æ®ä¸­ `status` æˆ– `payment_method` çš„å€¼ä¸ç¡®å®šï¼Œå»ºè®®å…ˆè¿è¡Œä»¥ä¸‹æŸ¥è¯¢æŸ¥çœ‹æ‰€æœ‰å¯èƒ½å€¼ï¼š\n\n```sql\nSELECT DISTINCT status FROM orders ORDER BY status;\nSELECT DISTINCT payment_method FROM orders ORDER BY payment_method;\n```\n\nç„¶åæ ¹æ®å®é™…å€¼è°ƒæ•´ `CASE` è¯­å¥ä¸­çš„å­—ç¬¦ä¸²ã€‚\n\n> âœ… æ­¤æŸ¥è¯¢å…¼å®¹å¤§å¤šæ•° SQL æ•°æ®åº“ï¼ˆMySQLã€PostgreSQLã€SQLiteã€SQL Server ç­‰ï¼‰ï¼Œæ˜¯å®ç°äº¤å‰è¡¨çš„é€šç”¨æ–¹æ³•ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 38, "group_id": 38, "sample_metadata": {}}}
{"index": 71, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªæµè§ˆå™¨åœ¨ä¸åŒè®¾å¤‡ç±»å‹ä¸‹çš„æ—¥å¿—æ•°é‡ï¼Œä½¿ç”¨äº¤å‰è¡¨æ ¼å¼æ˜¾ç¤ºã€‚\nSQL:", "target": "SELECT browser, SUM(CASE WHEN device_type = 'desktop' THEN 1 ELSE 0 END) as desktop_count, SUM(CASE WHEN device_type = 'mobile' THEN 1 ELSE 0 END) as mobile_count, SUM(CASE WHEN device_type = 'tablet' THEN 1 ELSE 0 END) as tablet_count FROM user_interaction_logs GROUP BY browser;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.52}, "extracted_prediction": "SELECT      browser,     SUM(CASE WHEN device_type = 'desktop' THEN 1 ELSE 0 END) AS desktop,     SUM(CASE WHEN device_type = 'mobile' THEN 1 ELSE 0 END) AS mobile,     SUM(CASE WHEN device_type = 'tablet' THEN 1 ELSE 0 END) AS tablet,     SUM(CASE WHEN device_type = 'other' THEN 1 ELSE 0 END) AS other,     COUNT(*) AS total FROM user_interaction_logs WHERE browser IS NOT NULL AND device_type IS NOT NULL GROUP BY browser ORDER BY browser", "prediction": "è¦å°†é—®é¢˜â€œç»Ÿè®¡æ¯ä¸ªæµè§ˆå™¨åœ¨ä¸åŒè®¾å¤‡ç±»å‹ä¸‹çš„æ—¥å¿—æ•°é‡ï¼Œä½¿ç”¨äº¤å‰è¡¨æ ¼å¼æ˜¾ç¤ºâ€è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ **æ¡ä»¶èšåˆï¼ˆConditional Aggregationï¼‰** æˆ– **PIVOT**ï¼ˆå¦‚æœæ•°æ®åº“æ”¯æŒï¼‰æ¥ç”Ÿæˆäº¤å‰è¡¨ï¼ˆå³è¡Œæ˜¯æµè§ˆå™¨ï¼Œåˆ—æ˜¯è®¾å¤‡ç±»å‹ï¼Œå•å…ƒæ ¼æ˜¯æ—¥å¿—æ•°é‡ï¼‰ã€‚\n\nç”±äºæ ‡å‡† SQL æ²¡æœ‰ `PIVOT` è¯­æ³•ï¼ˆMySQL ä¸æ”¯æŒï¼ŒPostgreSQL/SQL Server æ”¯æŒä½†è¯­æ³•ä¸åŒï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨é€šç”¨çš„ **CASE + SUM** æ–¹æ³•å®ç°äº¤å‰è¡¨ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ•°æ®åº“ï¼ˆå¦‚ MySQLã€PostgreSQLã€SQLite ç­‰ï¼‰ã€‚\n\nå‡è®¾æˆ‘ä»¬ä¸çŸ¥é“æ‰€æœ‰è®¾å¤‡ç±»å‹çš„å®Œæ•´åˆ—è¡¨ï¼Œä½†æ ¹æ®å¸¸è§æƒ…å†µï¼Œè®¾å¤‡ç±»å‹å¯èƒ½åŒ…æ‹¬ï¼š`'desktop'`, `'mobile'`, `'tablet'`, `'other'`ã€‚æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨åˆ—å‡ºè¿™äº›å€¼ã€‚å¦‚æœè®¾å¤‡ç±»å‹æ˜¯åŠ¨æ€çš„ï¼Œéœ€è¦åŠ¨æ€ SQLï¼Œä½†é¢˜ç›®æœªè¯´æ˜ï¼Œæˆ‘ä»¬æŒ‰é™æ€å¤„ç†ã€‚\n\n### SQL æŸ¥è¯¢ï¼ˆäº¤å‰è¡¨æ ¼å¼ï¼‰ï¼š\n```sql\nSELECT \n    browser,\n    SUM(CASE WHEN device_type = 'desktop' THEN 1 ELSE 0 END) AS desktop,\n    SUM(CASE WHEN device_type = 'mobile' THEN 1 ELSE 0 END) AS mobile,\n    SUM(CASE WHEN device_type = 'tablet' THEN 1 ELSE 0 END) AS tablet,\n    SUM(CASE WHEN device_type = 'other' THEN 1 ELSE 0 END) AS other,\n    COUNT(*) AS total\nFROM user_interaction_logs\nWHERE browser IS NOT NULL AND device_type IS NOT NULL\nGROUP BY browser\nORDER BY browser;\n```\n\n### è¯´æ˜ï¼š\n- `SUM(CASE WHEN ... THEN 1 ELSE 0 END)`ï¼šå¯¹æ¯ä¸ªè®¾å¤‡ç±»å‹è¿›è¡Œè®¡æ•°ï¼Œå½¢æˆåˆ—ã€‚\n- `GROUP BY browser`ï¼šæŒ‰æµè§ˆå™¨åˆ†ç»„ã€‚\n- `WHERE ... IS NOT NULL`ï¼šæ’é™¤ç©ºå€¼ï¼Œä¿è¯ç»Ÿè®¡å‡†ç¡®æ€§ã€‚\n- `COUNT(*) AS total`ï¼šå¯é€‰ï¼Œæ˜¾ç¤ºæ¯ä¸ªæµè§ˆå™¨çš„æ€»æ—¥å¿—æ•°ï¼Œä¾¿äºéªŒè¯ã€‚\n- ç»“æœè¡Œï¼šæ¯ä¸ªæµè§ˆå™¨ä¸€è¡Œï¼›åˆ—ï¼šæ¯ç§è®¾å¤‡ç±»å‹ä¸€åˆ—ï¼Œå€¼ä¸ºå¯¹åº”æ—¥å¿—æ•°é‡ã€‚\n\n> âœ… æ­¤æŸ¥è¯¢é€‚ç”¨äº MySQLã€PostgreSQLã€SQLiteã€SQL Serverï¼ˆä¸ä½¿ç”¨ PIVOT çš„æƒ…å†µä¸‹ï¼‰ç­‰ä¸»æµæ•°æ®åº“ã€‚\n\n### å¦‚æœä½ å¸Œæœ›åªæ˜¾ç¤ºè®¾å¤‡ç±»å‹åˆ—ï¼Œä¸åŒ…å« totalï¼š\n```sql\nSELECT \n    browser,\n    SUM(CASE WHEN device_type = 'desktop' THEN 1 ELSE 0 END) AS desktop,\n    SUM(CASE WHEN device_type = 'mobile' THEN 1 ELSE 0 END) AS mobile,\n    SUM(CASE WHEN device_type = 'tablet' THEN 1 ELSE 0 END) AS tablet,\n    SUM(CASE WHEN device_type = 'other' THEN 1 ELSE 0 END) AS other\nFROM user_interaction_logs\nWHERE browser IS NOT NULL AND device_type IS NOT NULL\nGROUP BY browser\nORDER BY browser;\n```\n\n> ğŸ’¡ **æç¤º**ï¼šå¦‚æœå®é™…æ•°æ®ä¸­è®¾å¤‡ç±»å‹æœ‰å…¶ä»–å€¼ï¼ˆå¦‚ `'laptop'`, `'tv'`ï¼‰ï¼Œè¯·æ ¹æ®çœŸå®æ•°æ®æ‰©å±• `CASE` è¯­å¥ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 71, "group_id": 71, "sample_metadata": {}}}
{"index": 7, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢å¹´é¾„åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„ç”¨æˆ·æ•°é‡ï¼ŒæŒ‰åŸå¸‚åˆ†ç»„ç»Ÿè®¡ã€‚\nSQL:", "target": "SELECT city, COUNT(*) as count FROM users WHERE age > (SELECT AVG(age) FROM users) GROUP BY city;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.975}, "extracted_prediction": "SELECT city, COUNT(*) AS user_count FROM users WHERE age > (SELECT AVG(age) FROM users) GROUP BY city", "prediction": "è¦æŸ¥è¯¢å¹´é¾„åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„ç”¨æˆ·æ•°é‡ï¼Œå¹¶æŒ‰åŸå¸‚åˆ†ç»„ç»Ÿè®¡ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ„å»º SQL æŸ¥è¯¢ï¼š\n\n1. è®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„å¹³å‡å¹´é¾„ã€‚\n2. ç­›é€‰å‡ºå¹´é¾„å¤§äºå¹³å‡å¹´é¾„çš„ç”¨æˆ·ã€‚\n3. æŒ‰åŸå¸‚ï¼ˆcityï¼‰åˆ†ç»„ï¼Œç»Ÿè®¡æ¯ç»„çš„ç”¨æˆ·æ•°é‡ã€‚\n\nå¯ä»¥ä½¿ç”¨å­æŸ¥è¯¢æ¥è®¡ç®—å¹³å‡å¹´é¾„ï¼Œç„¶ååœ¨ä¸»æŸ¥è¯¢ä¸­è¿‡æ»¤å¹¶åˆ†ç»„ã€‚\n\nä»¥ä¸‹æ˜¯å¯¹åº”çš„ SQL æŸ¥è¯¢ï¼š\n\n```sql\nSELECT city, COUNT(*) AS user_count\nFROM users\nWHERE age > (SELECT AVG(age) FROM users)\nGROUP BY city;\n```\n\n### è§£é‡Šï¼š\n- `(SELECT AVG(age) FROM users)`ï¼šè®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„å¹³å‡å¹´é¾„ã€‚\n- `WHERE age > ...`ï¼šç­›é€‰å‡ºå¹´é¾„é«˜äºå¹³å‡å€¼çš„ç”¨æˆ·ã€‚\n- `GROUP BY city`ï¼šæŒ‰åŸå¸‚åˆ†ç»„ã€‚\n- `COUNT(*) AS user_count`ï¼šç»Ÿè®¡æ¯ä¸ªåŸå¸‚ä¸­ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·æ•°é‡ã€‚\n\nè¿™ä¸ªæŸ¥è¯¢æ»¡è¶³é¢˜ç›®è¦æ±‚ï¼š**æŸ¥è¯¢å¹´é¾„åœ¨å¹³å‡å€¼ä»¥ä¸Šçš„ç”¨æˆ·æ•°é‡ï¼ŒæŒ‰åŸå¸‚åˆ†ç»„ç»Ÿè®¡**ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 7, "group_id": 7, "sample_metadata": {}}}
{"index": 12, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢æ¯ä¸ªåŸå¸‚ä¸­å¹´é¾„æœ€å¤§çš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºåŸå¸‚ã€ç”¨æˆ·åå’Œå¹´é¾„ã€‚\nSQL:", "target": "SELECT city, username, age FROM users u1 WHERE age = (SELECT MAX(age) FROM users u2 WHERE u2.city = u1.city);", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT city, username, age FROM users u1 WHERE age = (     SELECT MAX(age)     FROM users u2     WHERE u2.city = u1.city )", "prediction": "SELECT city, username, age\nFROM users u1\nWHERE age = (\n    SELECT MAX(age)\n    FROM users u2\n    WHERE u2.city = u1.city\n);", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 12, "group_id": 12, "sample_metadata": {}}}
{"index": 72, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE user_interaction_logs (log_id INT PRIMARY KEY, user_id INT, action_type TEXT, page_url TEXT, session_id TEXT, timestamp TIMESTAMP, ip_address TEXT, device_type TEXT, browser TEXT, duration INT, status_code INT);\nQuestion: æŸ¥è¯¢IPåœ°å€ä»¥192.168å¼€å¤´çš„æ—¥å¿—ï¼Œæ‰¾å‡ºæ¯ä¸ªç”¨æˆ·çš„æ“ä½œæ¬¡æ•°ï¼ŒæŒ‰æ“ä½œæ¬¡æ•°é™åºæ’åˆ—ï¼Œæ˜¾ç¤ºå‰50ä¸ªç”¨æˆ·ã€‚\nSQL:", "target": "SELECT user_id, COUNT(*) as action_count FROM user_interaction_logs WHERE ip_address LIKE '192.168%' GROUP BY user_id ORDER BY action_count DESC LIMIT 50;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT      user_id,      COUNT(*) AS action_count FROM      user_interaction_logs WHERE      ip_address LIKE '192.168%' GROUP BY      user_id ORDER BY      action_count DESC LIMIT 50", "prediction": "SELECT \n    user_id, \n    COUNT(*) AS action_count\nFROM \n    user_interaction_logs\nWHERE \n    ip_address LIKE '192.168%'\nGROUP BY \n    user_id\nORDER BY \n    action_count DESC\nLIMIT 50;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 72, "group_id": 72, "sample_metadata": {}}}
{"index": 34, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: ç»Ÿè®¡2023å¹´æ¯ä¸ªå­£åº¦çš„è®¢å•æ€»é‡‘é¢å’Œå¹³å‡è®¢å•é‡‘é¢ï¼ŒæŒ‰å­£åº¦æ’åºã€‚\nSQL:", "target": "SELECT CASE WHEN strftime('%m', order_date) IN ('01','02','03') THEN 'Q1' WHEN strftime('%m', order_date) IN ('04','05','06') THEN 'Q2' WHEN strftime('%m', order_date) IN ('07','08','09') THEN 'Q3' ELSE 'Q4' END as quarter, SUM(total_amount) as total, AVG(total_amount) as avg_amount FROM orders WHERE strftime('%Y', order_date) = '2023' GROUP BY quarter ORDER BY quarter;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.6246031746031746}, "extracted_prediction": "SELECT      QUARTER(order_date) AS quarter,     SUM(total_amount) AS total_order_amount,     AVG(total_amount) AS average_order_amount FROM      orders WHERE      YEAR(order_date) = 2023 GROUP BY      QUARTER(order_date) ORDER BY      quarter", "prediction": "SELECT \n    QUARTER(order_date) AS quarter,\n    SUM(total_amount) AS total_order_amount,\n    AVG(total_amount) AS average_order_amount\nFROM \n    orders\nWHERE \n    YEAR(order_date) = 2023\nGROUP BY \n    QUARTER(order_date)\nORDER BY \n    quarter;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 34, "group_id": 34, "sample_metadata": {}}}
{"index": 55, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æ‰¾å‡ºæ›´æ–°æ—¥æœŸè·ç¦»åˆ›å»ºæ—¥æœŸè¶…è¿‡1å¹´çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜ã€åˆ›å»ºæ—¥æœŸå’Œæ›´æ–°æ—¥æœŸã€‚\nSQL:", "target": "SELECT doc_id, title, created_date, updated_date FROM research_docs WHERE julianday(updated_date) - julianday(created_date) > 365;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT doc_id, title, created_date, updated_date FROM research_docs WHERE julianday(updated_date) - julianday(created_date) > 365", "prediction": "SELECT doc_id, title, created_date, updated_date\nFROM research_docs\nWHERE julianday(updated_date) - julianday(created_date) > 365;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 55, "group_id": 55, "sample_metadata": {}}}
{"index": 37, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢é…é€åœ°å€åŒ…å«'åŒ—äº¬'çš„è®¢å•ï¼Œç»Ÿè®¡æ¯ä¸ªçŠ¶æ€çš„è®¢å•æ•°é‡ã€‚\nSQL:", "target": "SELECT status, COUNT(*) as count FROM orders WHERE shipping_address LIKE '%åŒ—äº¬%' GROUP BY status;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.96875}, "extracted_prediction": "SELECT      status,      COUNT(*) AS order_count FROM      orders WHERE      shipping_address LIKE '%åŒ—äº¬%' GROUP BY      status", "prediction": "SELECT \n    status, \n    COUNT(*) AS order_count\nFROM \n    orders\nWHERE \n    shipping_address LIKE '%åŒ—äº¬%'\nGROUP BY \n    status;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 37, "group_id": 37, "sample_metadata": {}}}
{"index": 39, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢è®¢å•é‡‘é¢åœ¨1000åˆ°5000å…ƒä¹‹é—´ï¼Œä¸”åˆ›å»ºæ—¶é—´åœ¨æœ€è¿‘3ä¸ªæœˆå†…çš„è®¢å•ï¼ŒæŒ‰è®¢å•é‡‘é¢å‡åºæ’åˆ—ã€‚\nSQL:", "target": "SELECT * FROM orders WHERE total_amount BETWEEN 1000 AND 5000 AND created_at >= datetime('now', '-3 months') ORDER BY total_amount ASC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8846153846153846}, "extracted_prediction": "SELECT * FROM orders WHERE total_amount BETWEEN 1000 AND 5000   AND created_at >= CURRENT_DATE - INTERVAL '3 months' ORDER BY total_amount ASC", "prediction": "SELECT *\nFROM orders\nWHERE total_amount BETWEEN 1000 AND 5000\n  AND created_at >= CURRENT_DATE - INTERVAL '3 months'\nORDER BY total_amount ASC;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 39, "group_id": 39, "sample_metadata": {}}}
{"index": 6, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºç”¨æˆ·åé•¿åº¦å¤§äº8ä¸”åŒ…å«æ•°å­—çš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·åå’Œæ³¨å†Œæ—¥æœŸã€‚\nSQL:", "target": "SELECT username, registration_date FROM users WHERE LENGTH(username) > 8 AND username GLOB '*[0-9]*';", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9333333333333332}, "extracted_prediction": "SELECT username, registration_date FROM users WHERE LENGTH(username) > 8   AND username REGEXP '[0-9]'", "prediction": "SELECT username, registration_date\nFROM users\nWHERE LENGTH(username) > 8\n  AND username REGEXP '[0-9]';", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 6, "group_id": 6, "sample_metadata": {}}}
{"index": 60, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: ç»Ÿè®¡æ¯ä¸ªç±»åˆ«ä¸­æ–‡ä»¶å¤§å°æœ€å¤§çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºç±»åˆ«ã€æ–‡æ¡£IDã€æ ‡é¢˜å’Œå¤§å°ã€‚\nSQL:", "target": "SELECT category, doc_id, title, file_size FROM research_docs r1 WHERE file_size = (SELECT MAX(file_size) FROM research_docs r2 WHERE r2.category = r1.category);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.21250000000000002}, "extracted_prediction": "SELECT category, doc_id, title, file_size FROM (     SELECT category, doc_id, title, file_size,            ROW_NUMBER() OVER (PARTITION BY category ORDER BY file_size DESC) AS rn     FROM research_docs ) ranked WHERE rn = 1", "prediction": "è¦ç»Ÿè®¡æ¯ä¸ªç±»åˆ«ä¸­æ–‡ä»¶å¤§å°æœ€å¤§çš„æ–‡æ¡£ï¼Œå¹¶æ˜¾ç¤ºç±»åˆ«ã€æ–‡æ¡£IDã€æ ‡é¢˜å’Œå¤§å°ï¼Œå¯ä»¥ä½¿ç”¨çª—å£å‡½æ•° `ROW_NUMBER()` æŒ‰ç±»åˆ«åˆ†ç»„å¹¶æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åºï¼Œç„¶åé€‰å–æ¯ç»„çš„ç¬¬ä¸€æ¡è®°å½•ã€‚\n\nä»¥ä¸‹æ˜¯å¯¹åº”çš„ SQL æŸ¥è¯¢ï¼š\n\n```sql\nSELECT category, doc_id, title, file_size\nFROM (\n    SELECT category, doc_id, title, file_size,\n           ROW_NUMBER() OVER (PARTITION BY category ORDER BY file_size DESC) AS rn\n    FROM research_docs\n) ranked\nWHERE rn = 1;\n```\n\n### è¯´æ˜ï¼š\n- `PARTITION BY category`ï¼šæŒ‰ç±»åˆ«åˆ†ç»„ã€‚\n- `ORDER BY file_size DESC`ï¼šåœ¨æ¯ä¸ªç±»åˆ«å†…æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åˆ—ã€‚\n- `ROW_NUMBER()`ï¼šä¸ºæ¯ç»„ä¸­çš„è®°å½•åˆ†é…å”¯ä¸€åºå·ï¼Œæœ€å¤§çš„æ–‡ä»¶å¤§å°è·å¾—åºå· 1ã€‚\n- å¤–å±‚æŸ¥è¯¢ `WHERE rn = 1`ï¼šåªä¿ç•™æ¯ä¸ªç±»åˆ«ä¸­æ–‡ä»¶å¤§å°æœ€å¤§çš„é‚£ä¸€æ¡è®°å½•ã€‚\n\nè¿™æ ·å°±èƒ½å¾—åˆ°æ¯ä¸ªç±»åˆ«ä¸­æ–‡ä»¶æœ€å¤§çš„æ–‡æ¡£çš„ç±»åˆ«ã€IDã€æ ‡é¢˜å’Œå¤§å°ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 60, "group_id": 60, "sample_metadata": {}}}
{"index": 54, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢æ ‡ç­¾ä¸­åŒ…å«'æœºå™¨å­¦ä¹ 'çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºæ–‡æ¡£IDã€æ ‡é¢˜ã€ä½œè€…å’Œåˆ›å»ºæ—¥æœŸï¼ŒæŒ‰åˆ›å»ºæ—¥æœŸé™åºæ’åˆ—ï¼Œæ˜¾ç¤ºå‰30æ¡ã€‚\nSQL:", "target": "SELECT doc_id, title, author, created_date FROM research_docs WHERE tags LIKE '%æœºå™¨å­¦ä¹ %' ORDER BY created_date DESC LIMIT 30;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT doc_id, title, author, created_date FROM research_docs WHERE tags LIKE '%æœºå™¨å­¦ä¹ %' ORDER BY created_date DESC LIMIT 30", "prediction": "SELECT doc_id, title, author, created_date\nFROM research_docs\nWHERE tags LIKE '%æœºå™¨å­¦ä¹ %'\nORDER BY created_date DESC\nLIMIT 30;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 54, "group_id": 54, "sample_metadata": {}}}
{"index": 5, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢2023å¹´æ¯ä¸ªå­£åº¦æ³¨å†Œçš„ç”¨æˆ·æ•°é‡ï¼ŒæŒ‰å­£åº¦æ’åºã€‚\nSQL:", "target": "SELECT CASE WHEN strftime('%m', registration_date) IN ('01','02','03') THEN 'Q1' WHEN strftime('%m', registration_date) IN ('04','05','06') THEN 'Q2' WHEN strftime('%m', registration_date) IN ('07','08','09') THEN 'Q3' ELSE 'Q4' END as quarter, COUNT(*) as count FROM users WHERE strftime('%Y', registration_date) = '2023' GROUP BY quarter ORDER BY quarter;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.6330065359477124}, "extracted_prediction": "SELECT      QUARTER(registration_date) AS quarter,     COUNT(*) AS user_count FROM      users WHERE      YEAR(registration_date) = 2023 GROUP BY      QUARTER(registration_date) ORDER BY      quarter", "prediction": "SELECT \n    QUARTER(registration_date) AS quarter,\n    COUNT(*) AS user_count\nFROM \n    users\nWHERE \n    YEAR(registration_date) = 2023\nGROUP BY \n    QUARTER(registration_date)\nORDER BY \n    quarter;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 5, "group_id": 5, "sample_metadata": {}}}
{"index": 24, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢2023å¹´ä¸‹åŠå¹´ï¼ˆ7-12æœˆï¼‰æ³¨å†Œçš„ç”¨æˆ·ä¸­ï¼ŒæŒ‰æœˆä»½ç»Ÿè®¡æ³¨å†Œäººæ•°ï¼Œåªæ˜¾ç¤ºæ³¨å†Œäººæ•°æœ€å¤šçš„å‰3ä¸ªæœˆã€‚\nSQL:", "target": "SELECT strftime('%Y-%m', registration_date) as month, COUNT(*) as count FROM users WHERE strftime('%Y', registration_date) = '2023' AND CAST(strftime('%m', registration_date) AS INTEGER) BETWEEN 7 AND 12 GROUP BY month ORDER BY count DESC LIMIT 3;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.5737373737373738}, "extracted_prediction": "SELECT      strftime('%m', registration_date) AS month,     COUNT(*) AS registration_count FROM      users WHERE      registration_date >= '2023-07-01'      AND registration_date <= '2023-12-31' GROUP BY      strftime('%m', registration_date) ORDER BY      registration_count DESC LIMIT 3", "prediction": "SELECT \n    strftime('%m', registration_date) AS month,\n    COUNT(*) AS registration_count\nFROM \n    users\nWHERE \n    registration_date >= '2023-07-01' \n    AND registration_date <= '2023-12-31'\nGROUP BY \n    strftime('%m', registration_date)\nORDER BY \n    registration_count DESC\nLIMIT 3;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 24, "group_id": 24, "sample_metadata": {}}}
{"index": 36, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æ‰¾å‡ºæ¯ä¸ªç”¨æˆ·è®¢å•é‡‘é¢æœ€å¤§çš„è®¢å•ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€è®¢å•å·å’Œè®¢å•é‡‘é¢ã€‚\nSQL:", "target": "SELECT user_id, order_id, total_amount FROM orders o1 WHERE total_amount = (SELECT MAX(total_amount) FROM orders o2 WHERE o2.user_id = o1.user_id);", "sample_score": {"score": {"value": {"sql_ast_sim": 0.203030303030303}, "extracted_prediction": "SELECT      user_id,      order_id,      total_amount FROM (     SELECT          user_id,          order_id,          total_amount,         ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY total_amount DESC) AS rn     FROM orders ) ranked WHERE rn = 1", "prediction": "SELECT \n    user_id, \n    order_id, \n    total_amount\nFROM (\n    SELECT \n        user_id, \n        order_id, \n        total_amount,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY total_amount DESC) AS rn\n    FROM orders\n) ranked\nWHERE rn = 1;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 36, "group_id": 36, "sample_metadata": {}}}
{"index": 4, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: è®¡ç®—æ¯ä¸ªæ€§åˆ«ç”¨æˆ·çš„å¹³å‡å¹´é¾„ï¼Œå¹¶æ˜¾ç¤ºå¹³å‡å¹´é¾„å¤§äº30çš„æ€§åˆ«åˆ†ç»„ã€‚\nSQL:", "target": "SELECT gender, AVG(age) as avg_age FROM users GROUP BY gender HAVING AVG(age) > 30;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT gender, AVG(age) AS avg_age FROM users GROUP BY gender HAVING AVG(age) > 30", "prediction": "SELECT gender, AVG(age) AS avg_age\nFROM users\nGROUP BY gender\nHAVING AVG(age) > 30;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 4, "group_id": 4, "sample_metadata": {}}}
{"index": 53, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: ç»Ÿè®¡2023å¹´æ¯ä¸ªæœˆåˆ›å»ºçš„æ–‡æ¡£æ•°é‡ï¼Œåªæ˜¾ç¤ºåˆ›å»ºæ•°é‡è¶…è¿‡20çš„æœˆä»½ï¼ŒæŒ‰æœˆä»½æ’åºã€‚\nSQL:", "target": "SELECT strftime('%Y-%m', created_date) as month, COUNT(*) as count FROM research_docs WHERE strftime('%Y', created_date) = '2023' GROUP BY month HAVING COUNT(*) > 20 ORDER BY month;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9848484848484849}, "extracted_prediction": "SELECT      strftime('%Y-%m', created_date) AS month,     COUNT(*) AS doc_count FROM      research_docs WHERE      strftime('%Y', created_date) = '2023' GROUP BY      month HAVING      COUNT(*) > 20 ORDER BY      month", "prediction": "SELECT \n    strftime('%Y-%m', created_date) AS month,\n    COUNT(*) AS doc_count\nFROM \n    research_docs\nWHERE \n    strftime('%Y', created_date) = '2023'\nGROUP BY \n    month\nHAVING \n    COUNT(*) > 20\nORDER BY \n    month;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 53, "group_id": 53, "sample_metadata": {}}}
{"index": 20, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: è®¡ç®—æ¯ä¸ªåŸå¸‚ç”¨æˆ·çš„å¹³å‡æ³¨å†Œæ—¶é•¿ï¼ˆä»¥å¤©ä¸ºå•ä½ï¼‰ï¼Œæ˜¾ç¤ºåŸå¸‚å’Œå¹³å‡å¤©æ•°ã€‚\nSQL:", "target": "SELECT city, AVG(julianday('now') - julianday(registration_date)) as avg_days FROM users GROUP BY city;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.75}, "extracted_prediction": "SELECT      city,      AVG(JULIANDAY('now') - JULIANDAY(registration_date)) AS avg_days FROM      users WHERE      registration_date IS NOT NULL GROUP BY      city", "prediction": "SELECT \n    city, \n    AVG(JULIANDAY('now') - JULIANDAY(registration_date)) AS avg_days\nFROM \n    users\nWHERE \n    registration_date IS NOT NULL\nGROUP BY \n    city;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 20, "group_id": 20, "sample_metadata": {}}}
{"index": 3, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºé‚®ç®±åŸŸåæ˜¯gmail.comçš„ç”¨æˆ·ä¸­ï¼Œæ³¨å†Œæ—¶é—´æœ€æ—©çš„å‰5åç”¨æˆ·ã€‚\nSQL:", "target": "SELECT * FROM users WHERE email LIKE '%@gmail.com' ORDER BY registration_date ASC LIMIT 5;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT * FROM users WHERE email LIKE '%@gmail.com' ORDER BY registration_date ASC LIMIT 5", "prediction": "SELECT *\nFROM users\nWHERE email LIKE '%@gmail.com'\nORDER BY registration_date ASC\nLIMIT 5;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 3, "group_id": 3, "sample_metadata": {}}}
{"index": 52, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æŸ¥è¯¢ç‰ˆæœ¬å·ä¸ºv2.0åŠä»¥ä¸Šçš„æ–‡æ¡£ï¼Œç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ–‡æ¡£æ•°é‡ã€‚\nSQL:", "target": "SELECT category, COUNT(*) as count FROM research_docs WHERE CAST(SUBSTR(version, 2) AS REAL) >= 2.0 GROUP BY category;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7642045454545454}, "extracted_prediction": "SELECT category, COUNT(*) AS document_count FROM research_docs WHERE version >= 'v2.0' GROUP BY category", "prediction": "SELECT category, COUNT(*) AS document_count\nFROM research_docs\nWHERE version >= 'v2.0'\nGROUP BY category;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 52, "group_id": 52, "sample_metadata": {}}}
{"index": 27, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢2023å¹´æ¯ä¸ªæœˆçš„è®¢å•æ€»é‡‘é¢ï¼Œåªæ˜¾ç¤ºæ€»é‡‘é¢è¶…è¿‡50000å…ƒçš„æœˆä»½ã€‚\nSQL:", "target": "SELECT strftime('%Y-%m', order_date) as month, SUM(total_amount) as total FROM orders WHERE strftime('%Y', order_date) = '2023' GROUP BY month HAVING SUM(total_amount) > 50000 ORDER BY month;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9722222222222222}, "extracted_prediction": "SELECT      strftime('%Y-%m', order_date) AS month,     SUM(total_amount) AS total_monthly_amount FROM      orders WHERE      strftime('%Y', order_date) = '2023' GROUP BY      month HAVING      SUM(total_amount) > 50000 ORDER BY      month", "prediction": "SELECT \n    strftime('%Y-%m', order_date) AS month,\n    SUM(total_amount) AS total_monthly_amount\nFROM \n    orders\nWHERE \n    strftime('%Y', order_date) = '2023'\nGROUP BY \n    month\nHAVING \n    SUM(total_amount) > 50000\nORDER BY \n    month;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 27, "group_id": 27, "sample_metadata": {}}}
{"index": 23, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºæ³¨å†Œæ—¶é—´æœ€æ—©çš„ç”¨æˆ·æ‰€åœ¨çš„åŸå¸‚ï¼Œå¹¶æŸ¥è¯¢è¯¥åŸå¸‚æ‰€æœ‰ç”¨æˆ·çš„å¹³å‡å¹´é¾„ã€‚\nSQL:", "target": "SELECT city, AVG(age) as avg_age FROM users WHERE city = (SELECT city FROM users ORDER BY registration_date ASC LIMIT 1) GROUP BY city;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.7777777777777778}, "extracted_prediction": "SELECT AVG(age) AS average_age FROM users WHERE city = (     SELECT city     FROM users     ORDER BY registration_date ASC     LIMIT 1 )", "prediction": "è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦åˆ†ä¸¤æ­¥æ€è€ƒï¼š\n\n1. **æ‰¾å‡ºæ³¨å†Œæ—¶é—´æœ€æ—©çš„ç”¨æˆ·æ‰€åœ¨çš„åŸå¸‚**ï¼šå³åœ¨ `users` è¡¨ä¸­æ‰¾åˆ° `registration_date` æœ€å°çš„é‚£æ¡è®°å½•çš„ `city`ã€‚\n2. **æŸ¥è¯¢è¯¥åŸå¸‚æ‰€æœ‰ç”¨æˆ·çš„å¹³å‡å¹´é¾„**ï¼šç”¨ä¸Šä¸€æ­¥å¾—åˆ°çš„åŸå¸‚ï¼Œç­›é€‰å‡ºè¯¥åŸå¸‚çš„æ‰€æœ‰ç”¨æˆ·ï¼Œç„¶åè®¡ç®—ä»–ä»¬çš„å¹³å‡å¹´é¾„ `AVG(age)`ã€‚\n\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨å­æŸ¥è¯¢æ¥å®ç°ï¼š\n\n```sql\nSELECT AVG(age) AS average_age\nFROM users\nWHERE city = (\n    SELECT city\n    FROM users\n    ORDER BY registration_date ASC\n    LIMIT 1\n);\n```\n\n### è§£é‡Šï¼š\n- å­æŸ¥è¯¢ï¼š`SELECT city FROM users ORDER BY registration_date ASC LIMIT 1`  \n  â†’ æ‰¾å‡ºæ³¨å†Œæ—¶é—´æœ€æ—©çš„ç”¨æˆ·çš„æ‰€åœ¨åŸå¸‚ã€‚\n- å¤–å±‚æŸ¥è¯¢ï¼šåœ¨ `users` è¡¨ä¸­ç­›é€‰å‡ºè¯¥åŸå¸‚çš„æ‰€æœ‰ç”¨æˆ·ï¼Œè®¡ç®—å…¶å¹³å‡å¹´é¾„ã€‚\n\nè¿™ä¸ªæŸ¥è¯¢æ˜¯é«˜æ•ˆä¸”ç¬¦åˆè¦æ±‚çš„ã€‚", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 23, "group_id": 23, "sample_metadata": {}}}
{"index": 2, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢æœ€è¿‘30å¤©å†…ç™»å½•è¿‡ä¸”çŠ¶æ€ä¸ºæ´»è·ƒçš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·åã€é‚®ç®±å’Œæœ€åç™»å½•æ—¶é—´ã€‚\nSQL:", "target": "SELECT username, email, last_login_date FROM users WHERE status = 'active' AND last_login_date >= DATE('now', '-30 days');", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT username, email, last_login_date FROM users WHERE last_login_date >= DATE('now', '-30 days')   AND status = 'active'", "prediction": "SELECT username, email, last_login_date\nFROM users\nWHERE last_login_date >= DATE('now', '-30 days')\n  AND status = 'active';", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 2, "group_id": 2, "sample_metadata": {}}}
{"index": 33, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢ä½¿ç”¨ä¿¡ç”¨å¡æ”¯ä»˜ä¸”è®¢å•é‡‘é¢å¤§äº1000å…ƒçš„è®¢å•ï¼ŒæŒ‰ä¸‹å•æ—¶é—´é™åºæ’åˆ—ï¼Œæ˜¾ç¤ºå‰50æ¡ã€‚\nSQL:", "target": "SELECT * FROM orders WHERE payment_method = 'credit_card' AND total_amount > 1000 ORDER BY order_date DESC LIMIT 50;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.8666666666666666}, "extracted_prediction": "SELECT * FROM orders WHERE payment_method = 'ä¿¡ç”¨å¡' AND total_amount > 1000 ORDER BY created_at DESC LIMIT 50", "prediction": "SELECT *\nFROM orders\nWHERE payment_method = 'ä¿¡ç”¨å¡' AND total_amount > 1000\nORDER BY created_at DESC\nLIMIT 50;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 33, "group_id": 33, "sample_metadata": {}}}
{"index": 51, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE research_docs (doc_id INT PRIMARY KEY, title TEXT, author TEXT, category TEXT, file_size INT, created_date DATE, updated_date DATE, version TEXT, status TEXT, tags TEXT, description TEXT);\nQuestion: æ‰¾å‡ºæ¯ä¸ªä½œè€…åˆ›å»ºçš„æ–‡æ¡£ä¸­ï¼Œæ–‡ä»¶å¤§å°æœ€å¤§çš„æ–‡æ¡£ï¼Œæ˜¾ç¤ºä½œè€…ã€æ–‡æ¡£IDã€æ ‡é¢˜å’Œå¤§å°ã€‚\nSQL:", "target": "SELECT author, doc_id, title, file_size FROM research_docs r1 WHERE file_size = (SELECT MAX(file_size) FROM research_docs r2 WHERE r2.author = r1.author);", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT author, doc_id, title, file_size FROM research_docs r1 WHERE file_size = (     SELECT MAX(file_size)     FROM research_docs r2     WHERE r1.author = r2.author )", "prediction": "SELECT author, doc_id, title, file_size\nFROM research_docs r1\nWHERE file_size = (\n    SELECT MAX(file_size)\n    FROM research_docs r2\n    WHERE r1.author = r2.author\n);", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 51, "group_id": 51, "sample_metadata": {}}}
{"index": 19, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æ‰¾å‡ºæœ€åç™»å½•æ—¶é—´åœ¨æœ€è¿‘7å¤©å†…ï¼Œä¸”æ³¨å†Œæ—¶é—´è¶…è¿‡6ä¸ªæœˆçš„ç”¨æˆ·ï¼Œæ˜¾ç¤ºç”¨æˆ·åå’Œæœ€åç™»å½•æ—¶é—´ã€‚\nSQL:", "target": "SELECT username, last_login_date FROM users WHERE last_login_date >= DATE('now', '-7 days') AND registration_date < DATE('now', '-6 months');", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9393939393939394}, "extracted_prediction": "SELECT username, last_login_date FROM users WHERE last_login_date >= DATE('now', '-7 days')   AND registration_date <= DATE('now', '-6 months')", "prediction": "SELECT username, last_login_date\nFROM users\nWHERE last_login_date >= DATE('now', '-7 days')\n  AND registration_date <= DATE('now', '-6 months');", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 19, "group_id": 19, "sample_metadata": {}}}
{"index": 13, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: ç»Ÿè®¡2023å¹´æ¯ä¸ªæœˆæ–°å¢ç”¨æˆ·æ•°é‡ï¼Œåªæ˜¾ç¤ºæ–°å¢ç”¨æˆ·æ•°è¶…è¿‡50çš„æœˆä»½ã€‚\nSQL:", "target": "SELECT strftime('%Y-%m', registration_date) as month, COUNT(*) as count FROM users WHERE strftime('%Y', registration_date) = '2023' GROUP BY month HAVING COUNT(*) > 50 ORDER BY month;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.9848484848484849}, "extracted_prediction": "SELECT      strftime('%Y-%m', registration_date) AS month,     COUNT(*) AS new_user_count FROM      users WHERE      strftime('%Y', registration_date) = '2023' GROUP BY      month HAVING      COUNT(*) > 50 ORDER BY      month", "prediction": "SELECT \n    strftime('%Y-%m', registration_date) AS month,\n    COUNT(*) AS new_user_count\nFROM \n    users\nWHERE \n    strftime('%Y', registration_date) = '2023'\nGROUP BY \n    month\nHAVING \n    COUNT(*) > 50\nORDER BY \n    month;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 13, "group_id": 13, "sample_metadata": {}}}
{"index": 31, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE, total_amount DECIMAL(10,2), status TEXT, payment_method TEXT, shipping_address TEXT, discount DECIMAL(10,2), tax DECIMAL(10,2), created_at TIMESTAMP);\nQuestion: æŸ¥è¯¢æœ€è¿‘30å¤©å†…ä¸‹å•çš„è®¢å•ï¼Œè®¡ç®—æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»é‡‘é¢ï¼Œåªæ˜¾ç¤ºæ€»é‡‘é¢è¶…è¿‡5000å…ƒçš„ç”¨æˆ·ã€‚\nSQL:", "target": "SELECT user_id, SUM(total_amount) as total FROM orders WHERE order_date >= DATE('now', '-30 days') GROUP BY user_id HAVING SUM(total_amount) > 5000 ORDER BY total DESC;", "sample_score": {"score": {"value": {"sql_ast_sim": 0.6851851851851851}, "extracted_prediction": "SELECT      user_id,     SUM(total_amount) AS total_order_amount FROM      orders WHERE      order_date >= CURRENT_DATE - INTERVAL '30 days' GROUP BY      user_id HAVING      SUM(total_amount) > 5000", "prediction": "SELECT \n    user_id,\n    SUM(total_amount) AS total_order_amount\nFROM \n    orders\nWHERE \n    order_date >= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY \n    user_id\nHAVING \n    SUM(total_amount) > 5000;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 31, "group_id": 31, "sample_metadata": {}}}
{"index": 0, "input": "**User**: \nConvert the following question into a SQL query based on the provided schema.\nSchema: CREATE TABLE users (user_id INT PRIMARY KEY, username TEXT, email TEXT, age INT, gender TEXT, registration_date DATE, last_login_date DATE, status TEXT, city TEXT, phone TEXT);\nQuestion: æŸ¥è¯¢æ‰€æœ‰æ³¨å†Œæ—¶é—´åœ¨2023å¹´1æœˆ1æ—¥ä¹‹åä¸”å¹´é¾„åœ¨25åˆ°35å²ä¹‹é—´çš„ç”¨æˆ·ï¼ŒæŒ‰æ³¨å†Œæ—¶é—´é™åºæ’åˆ—ï¼Œåªæ˜¾ç¤ºå‰10æ¡ã€‚\nSQL:", "target": "SELECT * FROM users WHERE registration_date > '2023-01-01' AND age BETWEEN 25 AND 35 ORDER BY registration_date DESC LIMIT 10;", "sample_score": {"score": {"value": {"sql_ast_sim": 1.0}, "extracted_prediction": "SELECT * FROM users WHERE registration_date > '2023-01-01'   AND age BETWEEN 25 AND 35 ORDER BY registration_date DESC LIMIT 10", "prediction": "SELECT *\nFROM users\nWHERE registration_date > '2023-01-01'\n  AND age BETWEEN 25 AND 35\nORDER BY registration_date DESC\nLIMIT 10;", "explanation": null, "metadata": {}, "main_score_name": "sql_ast_sim"}, "sample_id": 0, "group_id": 0, "sample_metadata": {}}}
