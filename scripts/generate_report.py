"""
å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆè„šæœ¬
================

ç”ŸæˆMarkdownæ ¼å¼çš„è¯„æµ‹ç»“æœå¯¹æ¯”æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python scripts/generate_report.py \
        --files results/llm/rag_qa/qwen2.5-7b_7B_20260111.json \
                results/llm/rag_qa/qwen2.5-32b_32B_20260111.json \
        --output reports/comparison_rag_qa.md
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List

import orjson

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import REPORTS_DIR


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ç”Ÿæˆè¯„æµ‹å¯¹æ¯”æŠ¥å‘Š")
    parser.add_argument(
        "--files",
        type=str,
        nargs="+",
        required=True,
        help="è¯„æµ‹ç»“æœæ–‡ä»¶è·¯å¾„åˆ—è¡¨",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„ (é»˜è®¤: reports/comparison_{timestamp}.md)",
    )
    parser.add_argument(
        "--title",
        type=str,
        default="æ¨¡å‹è¯„æµ‹å¯¹æ¯”æŠ¥å‘Š",
        help="æŠ¥å‘Šæ ‡é¢˜",
    )
    return parser.parse_args()


def load_result_file(file_path: str) -> Dict[str, Any]:
    """åŠ è½½è¯„æµ‹ç»“æœæ–‡ä»¶"""
    path = Path(file_path)
    if not path.exists():
        print(f"è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return {}
    
    with open(path, "r", encoding="utf-8") as f:
        return orjson.loads(f.read())


def generate_markdown_report(
    results: List[Dict[str, Any]],
    title: str,
) -> str:
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š
    
    Args:
        results: è¯„æµ‹ç»“æœåˆ—è¡¨
        title: æŠ¥å‘Šæ ‡é¢˜
        
    Returns:
        Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
    """
    lines = []
    
    # æ ‡é¢˜
    lines.append(f"# {title}")
    lines.append("")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    
    # æ±‡æ€»ä¿¡æ¯
    lines.append("## ğŸ“Š è¯„æµ‹æ¦‚è§ˆ")
    lines.append("")
    lines.append("| æ¨¡å‹ | å‚æ•°é‡ | ç±»å‹ | æ•°æ®é›† | æ ·æœ¬æ•° |")
    lines.append("|------|--------|------|--------|--------|")
    
    for result in results:
        model_name = result.get("model_name", "æœªçŸ¥")
        param_size = result.get("param_size", "æœªçŸ¥")
        model_type = result.get("model_type", "æœªçŸ¥")
        dataset = result.get("dataset", "æœªçŸ¥")
        sample_count = len(result.get("details", []))
        
        lines.append(f"| {model_name} | {param_size} | {model_type} | {dataset} | {sample_count} |")
    
    lines.append("")
    
    # æŒ‡æ ‡å¯¹æ¯”è¡¨
    lines.append("## ğŸ“ˆ æŒ‡æ ‡å¯¹æ¯”")
    lines.append("")
    
    # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
    all_metrics = set()
    for result in results:
        all_metrics.update(result.get("metrics", {}).keys())
    
    if all_metrics:
        # è¡¨å¤´
        header = "| æ¨¡å‹ | å‚æ•°é‡ |"
        separator = "|------|--------|"
        for metric in sorted(all_metrics):
            header += f" {metric} |"
            separator += "--------|"
        
        lines.append(header)
        lines.append(separator)
        
        # æ•°æ®è¡Œ
        for result in results:
            model_name = result.get("model_name", "æœªçŸ¥")
            param_size = result.get("param_size", "æœªçŸ¥")
            metrics = result.get("metrics", {})
            
            row = f"| {model_name} | {param_size} |"
            for metric in sorted(all_metrics):
                value = metrics.get(metric, "-")
                if isinstance(value, float):
                    row += f" {value:.4f} |"
                else:
                    row += f" {value} |"
            
            lines.append(row)
        
        lines.append("")
    
    # æœ€ä½³æ¨¡å‹
    lines.append("## ğŸ† æœ€ä½³è¡¨ç°")
    lines.append("")
    
    for metric in sorted(all_metrics):
        best_model = None
        best_score = -1
        
        for result in results:
            score = result.get("metrics", {}).get(metric, -1)
            if isinstance(score, (int, float)) and score > best_score:
                best_score = score
                best_model = result.get("model_name", "æœªçŸ¥")
        
        if best_model:
            lines.append(f"- **{metric}**: {best_model} ({best_score:.4f})")
    
    lines.append("")
    
    # é…ç½®ä¿¡æ¯
    lines.append("## âš™ï¸ è¯„æµ‹é…ç½®")
    lines.append("")
    
    for result in results:
        model_name = result.get("model_name", "æœªçŸ¥")
        config = result.get("config", {})
        timestamp = result.get("timestamp", "æœªçŸ¥")
        
        lines.append(f"### {model_name}")
        lines.append("")
        lines.append(f"- è¯„æµ‹æ—¶é—´: {timestamp}")
        
        for key, value in config.items():
            lines.append(f"- {key}: {value}")
        
        lines.append("")
    
    # è¯¦ç»†ç»“æœæ ·ä¾‹
    lines.append("## ğŸ“ ç»“æœæ ·ä¾‹")
    lines.append("")
    lines.append("ä»¥ä¸‹å±•ç¤ºæ¯ä¸ªæ¨¡å‹çš„å‰3æ¡ç»“æœæ ·ä¾‹ï¼š")
    lines.append("")
    
    for result in results:
        model_name = result.get("model_name", "æœªçŸ¥")
        details = result.get("details", [])[:3]  # å–å‰3æ¡
        
        lines.append(f"### {model_name}")
        lines.append("")
        
        for i, detail in enumerate(details, 1):
            lines.append(f"**æ ·ä¾‹ {i}** (ID: {detail.get('id', 'æœªçŸ¥')})")
            lines.append("")
            
            # æ˜¾ç¤ºåˆ†æ•°
            scores = detail.get("scores", {})
            scores_str = ", ".join([f"{k}={v:.4f}" if isinstance(v, float) else f"{k}={v}" for k, v in scores.items()])
            lines.append(f"- åˆ†æ•°: {scores_str}")
            
            # æ˜¾ç¤ºé¢„æµ‹å’Œå‚è€ƒ (å¦‚æœæœ‰)
            if "prediction" in detail:
                pred = detail["prediction"]
                if len(pred) > 200:
                    pred = pred[:200] + "..."
                lines.append(f"- é¢„æµ‹: {pred}")
            
            if "reference" in detail:
                ref = detail["reference"]
                if len(ref) > 200:
                    ref = ref[:200] + "..."
                lines.append(f"- å‚è€ƒ: {ref}")
            
            lines.append("")
    
    return "\n".join(lines)


def main():
    args = parse_args()
    
    # åŠ è½½æ‰€æœ‰ç»“æœæ–‡ä»¶
    results = []
    for file_path in args.files:
        result = load_result_file(file_path)
        if result:
            results.append(result)
    
    if not results:
        print("é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœæ–‡ä»¶")
        sys.exit(1)
    
    print(f"å·²åŠ è½½ {len(results)} ä¸ªç»“æœæ–‡ä»¶")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_markdown_report(results, args.title)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        REPORTS_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = REPORTS_DIR / f"comparison_{timestamp}.md"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å†™å…¥æŠ¥å‘Š
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


if __name__ == "__main__":
    main()

